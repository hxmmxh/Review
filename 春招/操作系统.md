- [概述](#概述)
  - [操作系统基本特征](#操作系统基本特征)
  - [操作系统的抽象](#操作系统的抽象)
  - [操作系统基本功能](#操作系统基本功能)
  - [用户态和内核态](#用户态和内核态)
    - [用户态到内核态的转换](#用户态到内核态的转换)
  - [中断](#中断)
  - [中断和异常](#中断和异常)
  - [并发和并行](#并发和并行)
  - [大内核和微内核](#大内核和微内核)
  - [系统调用](#系统调用)
  - [局部性原理](#局部性原理)
- [进程](#进程)
  - [基本概念](#基本概念)
    - [僵尸进程和孤儿进程](#僵尸进程和孤儿进程)
    - [守护进程](#守护进程)
    - [让进程后台运行](#让进程后台运行)
    - [终端退出，终端运行的进程会怎样](#终端退出终端运行的进程会怎样)
  - [进程的五种状态](#进程的五种状态)
  - [进程终止的方式](#进程终止的方式)
  - [进程切换](#进程切换)
    - [上下文切换](#上下文切换)
    - [fork和vfork](#fork和vfork)
    - [父子进程共享和独有的资源](#父子进程共享和独有的资源)
  - [进程调度](#进程调度)
  - [进程间通信](#进程间通信)
  - [经典同步问题](#经典同步问题)
  - [信号量实现生产者和消费者](#信号量实现生产者和消费者)
  - [同步与异步](#同步与异步)
  - [并发与并行](#并发与并行)
  - [共享](#共享)
  - [两种类型的进程/线程](#两种类型的进程线程)
- [线程](#线程)
  - [线程共享和私有的的资源](#线程共享和私有的的资源)
  - [线程切换](#线程切换)
  - [一个进程可以创建多少线程](#一个进程可以创建多少线程)
  - [回收线程](#回收线程)
  - [线程同步机制](#线程同步机制)
  - [线程池](#线程池)
  - [常用线程模型](#常用线程模型)
- [线程Vs进程Vs协程](#线程vs进程vs协程)
  - [进程线程区别](#进程线程区别)
    - [进程和线程的选择](#进程和线程的选择)
  - [有了进程，为什么还要有线程](#有了进程为什么还要有线程)
  - [协程](#协程)
- [死锁](#死锁)
  - [可抢占资源和不可抢占资源](#可抢占资源和不可抢占资源)
  - [产生原因](#产生原因)
  - [解决方法](#解决方法)
  - [死锁避免方法](#死锁避免方法)
  - [- 对每个请求进行检查，检查是否请求会引起不安全状态，如果不会引起，那么就接受该请求；如果会引起，那么就推迟该请求。](#--对每个请求进行检查检查是否请求会引起不安全状态如果不会引起那么就接受该请求如果会引起那么就推迟该请求)
- [内存管理](#内存管理)
  - [物理内存四个层次](#物理内存四个层次)
  - [内存管理需要满足的需求](#内存管理需要满足的需求)
  - [地址空间](#地址空间)
  - [连续分配存储管理方式](#连续分配存储管理方式)
    - [单一连续存储管理](#单一连续存储管理)
    - [分区式存储管理](#分区式存储管理)
    - [空闲内存管理](#空闲内存管理)
  - [覆盖和交换技术](#覆盖和交换技术)
  - [内存交换中，被换出的进程保存在哪里？](#内存交换中被换出的进程保存在哪里)
- [虚拟内存](#虚拟内存)
  - [内存](#内存)
  - [什么是虚拟内存](#什么是虚拟内存)
  - [虚拟内存的好处和代价](#虚拟内存的好处和代价)
  - [分页技术](#分页技术)
    - [MMU的工作原理](#mmu的工作原理)
    - [页表](#页表)
    - [分页系统的问题](#分页系统的问题)
    - [转换检测缓冲区(Translation Lookaside Buffer, TLB)，快表](#转换检测缓冲区translation-lookaside-buffer-tlb快表)
    - [多级页表](#多级页表)
    - [倒排页表](#倒排页表)
  - [缺页中断](#缺页中断)
    - [缺页置换方法](#缺页置换方法)
    - [LRU的实现](#lru的实现)
    - [LRU-K的实现](#lru-k的实现)
  - [分段技术](#分段技术)
    - [段页式存储管理](#段页式存储管理)
    - [段页式管理每一次数据要访问几次内存?](#段页式管理每一次数据要访问几次内存)
    - [页和段的区别](#页和段的区别)
    - [内部碎片和外部碎片](#内部碎片和外部碎片)
  - [内存溢出和内存泄漏](#内存溢出和内存泄漏)
  - [* 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。](#-没有将基类的析构函数定义为虚函数当基类指针指向子类对象时如果基类的析构函数不是virtual那么子类的析构函数将不会被调用子类的资源没有正确是释放因此造成内存泄露)
- [IO](#io)
    - [标准io和文件io的区别](#标准io和文件io的区别)
- [信号](#信号)
  - [常见的信号](#常见的信号)

----------------------------------------------------
# 概述

## 操作系统基本特征
1. 并发
   - 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。
   - 并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。
   - 操作系统通过引入进程和线程，使得程序能够并发运行。
   - 并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。 
   - 并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。 
2. 共享
   - 共享是指系统中的资源可以被多个并发进程共同使用。
   - 有两种共享方式：互斥共享和同时共享。
   - 互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。
3. 虚拟
   - 虚拟技术把一个物理实体转换为多个逻辑实体。主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。
   - 多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。
   - 虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。
4. 异步
   - 异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。

## 操作系统的抽象

- 文件：对 I/O 设备的抽象
- 虚拟内存：对程序存储器的抽象
- 进程：对一个正在运行程序的抽象
- 虚拟机：对整个操作系统的抽象


## 操作系统基本功能
1. 进程管理  
进程控制、进程同步、进程通信、死锁处理、处理机调度等。
2. 内存管理  
内存分配、地址映射、内存保护与共享、虚拟内存等。
3. 文件管理  
文件存储空间的管理、目录管理、文件读写管理和保护等。
4. 设备管理  
完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。
主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

## 用户态和内核态
- 内核态与用户态是操作系统的两种运行级别
- 内核态拥有最高权限，可以访问所有系统指令；用户态则只能访问一部分指令
- 用户态下的程序不能直接访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。
- 为了安全性。在cpu的一些指令中，有的指令如果用错，将会导致整个系统崩溃。分了内核态和用户态后，当用户需要操作这些指令时候，内核为其提供了API，可以通过系统调用陷入内核，让内核去执行这些操作。

### 用户态到内核态的转换

- 系统调用   
  - 这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。
  - 而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的ine 80h中断。 
- 异常   
  - 当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此异常的内核相关程序中，也就到了内核态，比如缺页异常。 
- 外围设备的中断   
  - 当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 


## 中断
- 在中断出现之前，CPU对IO采用的是轮询的方式进行服务，这使的CPU纠结在某一个IO上，一直在等待它的响应，如果它不响应，CPU就在原地一直的等下去。这样就导致了其他IO口也在等待CPU的服务，如果某个IO出现了important or emergency affairs，CPU也抽不出身去响应这个IO。
- 中断控制的主要优点是只有在IO接口需要服务时才去响应它，使得CPU很淡定的做它自己的事情，只有IO口有需求的时候才去响应它。同时中断中也设计了中断优先级，来处理一些很紧急的事件。
- CPU获知了计算机中发生的某些事，暂停执行当前的程序，转而去执行处理该事件的程序，当这段程序执行完毕之后，CPU继续执行刚才的程序。整个过程称为中断处理
- 来自CPU外部的中断称为 外部中断，来自CPU内部的中断称为 内部中断。
- 外部中断按是否宕机可以分为 可屏蔽中断 和 不可屏蔽中断。
- 内部中断按中断是否正常又可分为 软中断 和 异常。

## 中断和异常

- 中段是由CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。
  - 一般由硬件设备产生的
  - 通过中断控制器发送给CPU，接着CPU判断收到的中断来自于哪个硬件设备（这定义在内核中），最后，由CPU发送给内核，有内核处理中断
- 而异常是由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。
- 中断不是时钟同步的，这意味着中断可能随时到来；异常由于是CPU产生的，所以它是时钟同步的

## 并发和并行

- 并发：对于单个CPU，在一个时刻只有一个进程在运行，但是线程的切换时间则减少到纳秒数量级，多个任务不停来回快速切换。
- 并行：对于多个CPU，多个进程同时运行。
- 区别。通俗来讲，它们虽然都说是"多个进程同时运行"，但是它们的"同时"不是一个概念。并行的"同时"是同一时刻可以多个任务在运行(处于running)，并发的"同时"是经过不同线程快速切换，使得看上去多个任务同时都在运行的

## 大内核和微内核
1. 大内核
   * 大内核是将操作系统功能作为一个紧密结合的整体放到内核。除了最基本的进程、线程管理、内存管理外，将文件系统，驱动，网络协议等等都集成在内核里面
   * 由于各模块共享信息，因此有很高的性能。
   * 缺点：稳定性差，开发过程中的bug经常会导致整个系统挂掉。
2. 微内核
   * 由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。内核中只有最基本的调度、内存管理。移出的部分根据分层的原则划分成若干服务，相互独立。
   * 在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。
   * 因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。
   * 稳定，驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃 


## 系统调用


## 局部性原理

- 时间局部性:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环) 
- 空间局部性:一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的)




-----------------------
# 进程

## 基本概念

- 进程可以认为是程序执行的一个实例，进程是系统进行资源分配的最小单位


### 僵尸进程和孤儿进程
- 父进程在调用fork接口之后和子进程已经可以独立开，之后父进程和子进程就以未知的顺序向下执行（异步过程）。所以父进程和子进程都有可能先执行完。
- 当父进程先结束，子进程此时就会变成孤儿进程，孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
- 僵尸进程 
   - 如果子进程先结束，父进程并未调用wait或者waitpid获取进程状态信息，那么子进程描述符就会一直保存在系统中，这种进程称为僵尸进程。
   - 保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。 
   - 解决方法
      - 通过kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源 
      - 子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。
      - 父进程调用wait/waitpid等函数等待子进程结束，如果尚无子进程退出wait会导致父进程阻塞。waitpid可以通过传递WNOHANG使父进程不阻塞立即返回。 
      - 通过signal(SIGCHLD, SIG_IGN)通知内核对子进程的结束不关心
      - fork两次，原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。 

### 守护进程

- 守护进程是脱离终端并在后台运行的进程，执行过程中信息不会显示在终端上并且也不会被终端发出的信号打断。
- 周期性地执行某种任务或等待处理某些发生的事件
- 创建流程
  - 1.调用umask将文件模式创建屏蔽字设置为一个已知值(通常是0)
    - 由继承而来的文件模式创建屏蔽字可能会被设置为拒绝某些权限，如果守护进程要创建文件，那么它可能要设置特定的权限
  - 2.调用fork，然后使父进程exit。这样做实现了以下几点
    - 如果该守护进程是作为一条简单的shell命令启动的，那么父进程终止会让shell认为这条命令已经执行完毕
    - 子进程继承了父进程的进程组ID,但获得了一个新的进程ID,保证了子进程不是一个进程组的组长进程，是下面调用setsid的先决条件
  - 3.调用setsid创建一个新会话。使调用进程成为新会话的首进程，成为新进程组的组长进程并且没有控制终端。
    - 但是在某些系统中，当会话首进程打开一个尚未与任何会话相关联的终端设备时，此设备会自动作为控制终端分配给该会话。这种情况下，可以再次调用fork,终止子进程，在孙子进程中创建守护进程，保证该守护进程不是会话首进程，防止它取得控制终端。
    - 还需要注意在会话首进程退出时，会对其所在会话的所有进程发送SIGHUP信号，而SIGHUP信号的默认处理函数结束进程。因此在孙子进程中需要忽略这一信号。
    - 还有一种方法是无论何时打开一个终端设备都一定要指定O_NOCTTY。
  - 4.将当前工作目录更改为根目录
    - 从父进程处继承过来的当前工作目录可能在一个挂载的文件系统中，因为守护进程通常在系统再引导之前是一直存在的，所以如果守护进程的当前工作目录在一个挂载文件系统中，那么该文件系统就不能被卸载。
  - 5.关闭不再需要的文件描述符。使守护进程不再持有从其父进程继承来的任何文件描述符
    - 可以用open_max函数或者getrlimit函数来判断最高文件描述符值，并关闭直到该值的所有描述符
  - 6.打开/dev/null使其具有文件描述符0、1、2，这样任何一个试图读标准输入、写标准输出或标准错误的库例程都不会产生任何效果
    - 不希望在终端上见到守护进程的输出
    - 也不希望在终端上的输入被守护进程读取

### 让进程后台运行

- 命令后面加上&即可
- ctrl + z 挂起进程

### 终端退出，终端运行的进程会怎样

- 终端在退出时会发送SIGHUP给对应的bash进程，bash进程收到这个信号后首先将它发给session下面的进程，如果程序没有对SIGHUP信号做特殊处理，那么进程就会随着终端关闭而退出

## 进程的五种状态
- 五种状态
  - 创建状态：进程正在被创建 
  - 就绪状态：进程被加入到就绪队列中等待CPU调度运行 
  - 执行状态：进程正在被运行 
  - 阻塞状态：进程因为某种原因，比如等待I/O，等待设备，而暂时不能运行。 
  - 终止状态：进程运行完毕 
- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。
  

## 进程终止的方式

1、main函数的自然返回，return 
2、调用exit函数，属于c的函数库 
3、调用_exit函数，属于系统调用 
4、调用abort函数，异常程序终止，同时发送SIGABRT信号给调用进程。 
5、接受能导致进程终止的信号：ctrl+c (^C)、SIGINT(SIGINT中断进程)

## 进程切换

- 从一个进程切换到另一个进程需要一定的时间进行管理处理
- 包括保存寄存器的值和内存映射、更新不同的表格和列表、清除和重新调入内存高速缓存等。这种切换称作 进程间切换(process switch) 和 上下文切换(context switch)

### 上下文切换

- 内核管理所有进程控制块，而进程控制块记录了进程全部状态信息。每一次进程调度就是一次上下文切换，
- 上下文本质上就是进程当前的运行状态，主要包括通用寄存器、浮点寄存器、状态寄存器、程序计数器、用户栈和内核数据结构（页表、进程表、文件表）等
- 一次完整的上下文切换通常是进程原先运行于用户态，之后因系统调用或时间片到切换到内核态执行内核指令，完成上下文切换后回到用户态，此时已经切换到进程B

### fork和vfork
- fork
   - 创建一个和当前进程映像一样的进程可以通过fork()系统调用
   - 成功调用fork()会创建一个新的进程，它几乎与调用fork()的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork()调用会返回0。在父进程中fork()返回子进程的pid。如果出现错误，fork()返回-1
   - 常用的fork()用法是创建一个新的进程，然后使用exec()载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像
   - 当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的
- vfork
   - vfork()会挂起父进程直到子进程终止或者运行了一个新的可执行文件的映像。通过这样的方式，vfork()避免了地址空间的按页复制
- 写时复制
   - 减少fork时对父进程空间进程整体复制带来的开销
   - 采取了惰性优化方法来避免复制时的系统开销
   - 如果有多个进程要读取它们自己的那部门资源的副本，那么复制是不必要的.如果一个进程要修改自己的那份资源“副本”，那么就会复制那份资源，并把复制的那份提供给进程
   - 写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行


### 父子进程共享和独有的资源

- 共享
  - 打开的文件
  - 对任一打开文件描述符的执行时关闭标志
- 区别
  - 

## 进程调度

- 什么时候需要进程调度
  - 当一个计算机是多道程序设计系统时，会频繁的有很多进程同时竞争 CPU 时间片。当两个或两个以上的进程/线程处于就绪状态时，就会发生这种情况。
  - 在创建一个新进程后，需要决定是运行父进程还是子进程
  - 在进程退出时需要作出调度决定，必须从就绪进程中选择其他进程运行
- 不同的环境下需要不同的调度算法
  - 不同的应用程序和不同的操作系统有不同的目标
- **批处理系统**
    - 应用于商业领域，比如用来处理工资单、存货清单、账目收入、账目支出、利息计算、索赔处理和其他周期性作业
    - 没有太多的用户操作,目标是保证吞吐量和周转时间（从提交到终止的时间）
    - 一般会选择使用非抢占式算法或者周期性比较长的抢占式算法。这种方法可以减少线程切换因此能够提升性能。
    - **先来先服务**
      - 按照请求的顺序进行调度。
      - 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。
    - **短作业优先**
      - 按估计运行时间最短的顺序进行调度。
      - 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。
    - **最短剩余时间优先**
      - 按剩余运行时间的顺序进行调度。
      - 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待
  - **交互式系统**
    - 有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。
    - 为了避免一个进程霸占 CPU 拒绝为其他进程服务，所以需要抢占式算法
    - **时间片轮转**
      - 维护一个可运行进程的队列，每次调度时把 CPU 时间分配给队首进程，该进程可以执行一个时间片。
      - 当时间片用完时，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。
      - 算法的效率和时间片的大小有很大关系
        - 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
        - 而如果时间片过长，那么实时性就不能得到保证
    - **优先级调度**
      - 每个进程都被赋予一个优先级，优先级高的进程优先运行
      - 不对优先级进行调整，则低优先级的进程很容易产生饥饿现象
      - 可以随着时间的推移增加等待进程的优先级
      - 或者在每个时钟中断期间降低当前运行进程的优先级
    - **多级反馈队列**
      - 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。
      - 设置了多个队列，每个队列时间片大小都不同。例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列
      - 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程
      - 属于最高优先级的进程运行一个时间片，次高优先级进程运行 2 个时间片，再下面一级运行 4 个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。
  - **实时系统**
    - 硬实时(hard real time) 和 软实时(soft real time) 系统，前者意味着必须要满足绝对的截止时间；后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。
    - 抢占有时是不需要的，因为进程知道自己可能运行不了很长时间，通常很快的做完自己的工作并阻塞。
    - 实时系统与交互式系统的差别是，实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的，它可以运行任意的非协作甚至是有恶意的程序


## 进程间通信 
- 1.管道
  - 无名管道
    - 无名管道是一种特殊的文件，这种文件只存在于内存中。
    - 无名管道只能用于父子进程或兄弟进程之间，必须用于具有亲缘关系的进程间的通信。
    - 无名管道只能由一端向另一端发送数据，是半双工方式，如果双方需要同时收发数据需要两个管道。
    - 相关接口：int pipe(int fd[2]);fd[2]：管道两端用fd[0]和fd[1]来描述，读的一端用fd[0]表示，写的一端用fd[1]表示。通信双方的进程中写数据的一方需要把fd[0]先close掉，读的一方需要先把fd[1]给close掉。
    - 使用步骤
      - 父进程调用pipe开辟管道,得到两个文件描述符指向管道的两端。
      - 父进程调用fork创建子进程,那么子进程也有两个文件描述符指向同一管道。
      - 父进程关闭管道读端,子进程关闭管道写端。父进程可以往管道里写,子进程可以从管道里读,管道是用环形队列实现的,数据从写端流入从读端流出,这样就实现了进程间通信
  - 有名管道：
    - 有名管道是FIFO文件，存在于文件系统中，可以通过文件路径名来指出。
    - 无名管道可以在不具有亲缘关系的进程间进行通信。
    - 相关接口：int mkfifo(const char *pathname, mode_t mode);pathname：即将创建的FIFO文件路径，如果文件存在需要先删除。mode：和open()中的参数相同。
- 2.信号
  - 向一个进程通知发生异步事件的机制
- 3.消息队列
  - 消息队列，是消息的链接表，存放在内核中。
  - 一个消息队列由一个标识符（即队列ID）来标记。
  - 具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息； 
- 4.共享内存
  - 多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新
  - 进程可以将同一段共享内存连接到它们自己的地址空间，所有进程都可以访问共享内存中的地址，如果某个进程向共享内存内写入数据，所做的改动将立即影响到可以访问该共享内存的其他所有进程。
- 5.信号量
  - 本质上是一个计数器，用于多进程对共享数据对象的读取，它主要是用来保护共享资源（信号量也属于临界资源），使得资源在一个时刻只有一个进程独享。
  - 信号量只能进行两种操作等待和发送信号，即P(sv)和V(sv)
    - P(sv)操作(down)：如果sv的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行（信号量的值为正，进程获得该资源的使用权，进程将信号量减1，表示它使用了一个资源单位）
    - V(sv)操作(up)：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加1（若此时信号量的值为0，则进程进入挂起状态，直到信号量的值大于0，若进程被唤醒则返回至第一步）
  - 如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。
- 6.套接字
  - 可用于不同主机之间的进程通信

## 经典同步问题
- 生产者-消费者问题
  - 使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品
- 读者-写者问题
  - 许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。
- 哲学家进餐问题
  - 哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。
  - 如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁
  - 为了防止死锁的发生，可以设置两个条件
    - 必须同时拿起左右两根筷子；
    - 只有在两个邻居都没有进餐的情况下才允许进餐。

## 信号量实现生产者和消费者

- 不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。
- 如果这么做了，那么可能会出现这种情况
  - 生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。
  - 消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。


```cpp
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

## 同步与异步
- 同步的含义
  - 就是调用一个过程时，假如过程还在执行状态，没有返回结果，那么在该过程返回之前，就不能继续做下一件事情。
  - 同步的特点就是：顺序性、确定性、简易性。
    - 顺序性，就是运行次序不会颠倒错乱，一切按顺序来；
    - 确定性，就是运行顺序是确定的，可以预见的，就像数学的计算过程一样，最后的答案是确定的；
    - 简易性，因为同步不牵涉到线程的概念，运行一个简单的单线程程序时，不会用到系统提供的线程同步机制（API）。
- 异步的含义
  - 异步是相对于同步而言的，意思与同步相反。即调用一个过程时，就接着做下面的事情，不立即获得该过程的返回值。
  - 因此，要实现异步，你得学会做两件事——添加新任务（创建线程），知道旧任务已经结束了并跑去处理（状态、通知和回调）。
- 实现异步的方法
  - 状态，即设一共享变量（FLAG），旧任务结束时，变量置有效值，之后旧任务结束，新任务循环检测变量是否有效；
  - 通知，即像下载软件一样，下载完，系统会通知你，即旧任务向新任务发通知或消息，发完之后，旧任务结束；
  - 回调，就是把旧任务做完后要做的收尾工作交给旧任务本身，这样，旧任务做完收尾工作后便结束。
  - 上述三种方法当中，“回调”，旧任务与新任务之间没有关系；“通知”，旧任务和新任务有直接联系；“状态”，旧任务和新任务有间接联系，通过状态变量。
    - 回调时，新任务可以不管旧任务的事情；
    - 通知时，新任务必须间断地等待是否有通知，如果有通知，就处理它。等待的时候，新任务一般处于阻塞状态；
    - 状态时，新任务不必进行等待操作，它只需要适时检测（判断）这个状态变量是否有效（即是否为有效值）就可以了，这种方法也就是轮询


## 并发与并行
- 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令
- 并发
  - 当有多个进程在运行时，如果系统是单核的CPU，那它根本不可能真正地同时运行一个以上的进程。
  - 系统只能把CPU运行时间划分成若干个时间段（在每个时刻段的起始时刻使用调度算法分配任务），再将每个时间段分配给每个进程执行。在一个时间段内，某进程在运行时，其它进程处于挂起状态（就绪状态）。这种方式我们称之为并发（Concurrent）
  - 并发的精髓就是分配时间片，微观上是间断的，宏观上是连续的。
- 并行
  - 并行是指两个或者多个事件在同一时刻发生；并发是指两个或多个事件在同一时间间隔内发生
  - 物理意义上的同时运行
  - 当系统有一个以上CPU（即多核）时，当一个CPU执行一个线程时，另一个CPU可以执行另一个线程，两个线程互不抢占CPU资源，可以同时进行，这种方式我们称之为并行（Parallel）
- 并发和并行的区别
  - 并行的程序比并发的程序效率高，资源利用率高，但编程更复杂，且结果不可预见，调试困难；
  - 并行会有对资源的争夺，而并发不会（某时刻只有一个程序独占资源），因而并行会有互斥与同步问题，还有由此导致的死锁问题；
  - 并发是单核CPU的产物，微观上间断，宏观上连续；并行是多核CPU的产物，微观上更连续，宏观上更连续。

## 共享

- 共享是指系统中的资源可以被多个并发进程共同使用。
- 有两种共享方式：互斥共享和同时共享。
- 互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。


## 两种类型的进程/线程

- CPU 密集型进程
  - 在计算的时间上花费时间更长，也被称为计算密集型(compute-bound) 
  - 有较长的 CPU 集中使用和较小频度的 I/O 等待
- I/O 密集型进程进程
  - 有较短的 CPU 使用时间和较频繁的 I/O 等待
  - 因为或者 CPU 密集型(CPU-bound) ，b 因为I/O 发生频率比较快因此称为 I/O 密集型(I/O-bound)。计算密集型进程。I/O 密集型进程。注意到上面两种进程的区分关键在于 CPU 的时间占用而不是 I/O 的时间占用。I/O 密集型的原因是因为它们没有在 I/O 之间花费更多的计算、而不是 I/O 请求时间特别长。无论数据到达后需要花费多少时间，它们都需要花费相同的时间来发出读取磁盘块的硬件请求。


# 线程

- 线程是操作系统调度的基本单位；
- 线程的状态切换比进程更迅速且开销更小；
- 线程不拥有资源，只是任务的一种抽象，同一进程内的线程共享该进程的资源；
- 对单核CPU而言，同一时刻只能运行一个线程；
- 一个进程至少有一个线程，且是它的主线程。

## 线程共享和私有的的资源
- 线程共享资源
  - 堆。由于堆是在进程空间中开辟出来的，所以它是理所当然地被共享的；因此new出来的都是共享的
  - 全局变量和静态变量，存于堆中开辟的.bss和.data段，是共享的
  - 文件描述符
  - 进程的当前目录和进程用户ID与进程组ID。
  - 信号的处理器
- 线程独享资源  
  - 线程ID，每个线程都有自己的线程ID，这个ID在本进程中是唯一的。进程用此来标识线程。  
  - 寄存器组的值。由于线程间是并发运行的，每个线程有自己不同的运行线索，当从一个线程切换到另一个线程上时，必须将原有的线程的寄存器集合的状态保存，以便将来该线程在被重新切换到时能得以恢复。  
  - 线程的栈。栈是保证线程独立运行所必须的。线程函数可以调用函数，而被调用函数中又是可以层层嵌套的，所以线程必须拥有自己的函数堆栈， 使得函数调用可以正常执行，不受其他线程的影响。  
  - 错误返回码。由于同一个进程中有很多个线程在同时运行，可能某个线程进行系统调用后设置了errno值，而在该 线程还没有处理这个错误，另外一个线程就在此时被调度器投入运行，这样错误值就有可能被修改。所以，不同的线程应该拥有自己的错误返回码变量。  
  - 线程的信号屏蔽码。由于每个线程所感兴趣的信号不同，所以线程的信号屏蔽码应该由线程自己管理。但所有的线程都 共享同样的信号处理器。  
  - 线程的优先级。由于线程需要像进程那样能够被调度，那么就必须要有可供调度使用的参数，这个参数就是线程的优先级。
  
## 线程切换

- 线程在切换的过程中需要保存当前线程Id、线程状态、栈、寄存器状态等信息。
- 其中寄存器主要包括SP PC EAX等寄存器，其主要功能如下：
  - SP:堆栈指针，指向当前栈的栈顶地址
  - PC:程序计数器，存储下一条将要执行的指令
  - EAX:累加寄存器，用于加法乘法的缺省寄存器

## 一个进程可以创建多少线程
- 一个进程可以创建的线程数由进程可用虚拟空间大小和线程的栈的大小共同决定，只要虚拟空间足够，那么新线程的建立就会成功
- 默认一个进程可用虚拟空间是2G，线程的栈的大小是1MB，所以理论上最多只能创建2048个线程。如果要创建多于2048的话，必须修改编译器的设置。

## 回收线程
- 等待线程结束：`int pthread_join(pthread_t tid, void** retval);`
  - 主线程调用，等待子线程退出并回收其资源，类似于进程中wait/waitpid回收僵尸进程，调用pthread_join的线程会被阻塞。
  - tid：创建线程时通过指针得到tid值。
  - retval：指向返回值的指针。
- 结束线程：`pthread_exit(void *retval)`
  - 子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过pthread_join获得。
  - retval：同上。
- 分离线程：`int pthread_detach(pthread_t tid);`
  - 主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中pthread_detach(pthread_self())，调用后和主线程分离，子线程结束时自己立即回收资源。
  - tid：同上


## 线程同步机制
- 如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。
- 线程安全问题都是由全局变量及静态变量引起的（？？）
- 若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。
- **互斥锁**：
  - mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。 
- **条件变量**
  - 常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。
  - 一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程
- **读写锁**
  - rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 
  - 写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。
  - 适用于读取数据的频率远远大于写数据的频率的场合。 
- **自旋锁**
  - spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡眠，而是会一直循环尝试获取锁，直到锁被释放。
  - 这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。 
- **屏障**
  - 用户协调多个线程并行工作的同步机制。
  - 屏障允许每个线程等待，直到所有的合作线程都到达某一点，然后从该点继续执行
- 互斥锁和读写锁的区别： 
 - 读写锁区分读者和写者，而互斥锁不区分 
 - 互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。 
- 互斥锁和自旋锁
  - 互斥锁用于临界区持锁时间比较长的操作，比如下面这些情况都可以考虑
    - 临界区有IO操作
    - 临界区代码复杂或者循环量大
    - 临界区竞争非常激烈
    - 单核处理器
  - 自旋锁就主要用在临界区持锁时间非常短且CPU资源不紧张的情况下。
- 也包括信号和信号量

## 线程池
- 即时创建，即使销毁策略的弊端   
  - 一旦有个请求到达，就创建一个新的线程，由该线程执行任务，任务执行完毕之后，线程就退出。这就是”即时创建，即时销毁”的策略。
  - 尽管与创建进程相比，创建线程的时间已经大大的缩短，但是如果提交给线程的任务是执行时间较短，而且执行次数非常频繁，那么服务器就将处于一个不停的创建线程和销毁线程的状态。这笔开销是不可忽略的，尤其是线程执行的时间非常非常短的情况。
- 线程池
  - 设置一个生产者消费者队列，作为临界资源。任务队列为空时，所有线程阻塞
  - 创建一定数量的线程，并让其运行起来，一开始这些线程都是处于阻塞状态，这些线程只占一点内存，不占用CPU。
  - 当任务到来后，先对队列加锁，把任务挂到队列上，然后使用条件变量去通知阻塞中的一个线程来处理
  - 当所有的线程都处在处理任务的时候，线程池将自动创建一定的数量的新线程，用于处理更多的任务。执行任务完成之后线程并不退出，而是继续在线程池中等待下一次任务。
  - 当大部分线程处于阻塞状态时，线程池将自动销毁一部分的线程，回收系统资源。
  - 需要大量的线程来完成任务，且完成任务的时间比较短；对性能要求苛刻的应用；对性能要求苛刻的应用
  - 线程池线程数量
    - 线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程
- 内存池
  - 在软件开发中，有些对象使用非常频繁，那么我们可以预先在堆中实例化一些对象，我们把维护这些对象的结构叫“内存池”。在需要用的时候，直接从内存池中拿，而不用从新实例化，在要销毁的时候，不是直接free/delete，而是返还给内存池。
  - 把那些常用的对象存在内存池中，就不用频繁的分配/回收内存，可以相对减少内存碎片，更重要的是实例化这样的对象更快，回收也更快。当内存池中的对象不够用的时候就扩容。
  - 内存池对象不是线程安全的，在多线程编程中，创建一个对象时必须加锁。


## 常用线程模型 
1. Future模型 
   - 该模型通常在使用的时候需要结合Callable接口配合使用。 
   - Future是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。 
   - Callable是类似于Runnable的接口，其中call方法类似于run方法，所不同的是run方法不能抛出受检异常没有返回值，而call方法则可以抛出受检异常并可设置返回值。两者的方法体都是线程执行体。 
2. fork&join模型 
   - 该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一些可以进行拆分的大任务。
   - 其主要是把一个大任务逐级拆分为多个子任务，然后分别在子线程中执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果。   
3. 生产者-消费者模型 
   - 使用一个缓存来保存任务。开启一个/多个线程来生产任务，然后再开启一个/多个来从缓存中取出任务进行处理。
   - 这样的好处是任务的生成和处理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费者只需要从缓存中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。比如，生成的任务速度较快，那么就可以灵活的多开启几个消费者线程进行处理，这样就可以避免任务的处理响应缓慢的问题。 
4. master-worker模型 
   - master-worker模型类似于任务分发策略，开启一个master线程接收任务，然后在master中根据任务的具体情况进行分发给其它worker子线程，然后由子线程处理任务。如需返回结果，则worker处理结束之后把处理结果返回给master。 


  


# 线程Vs进程Vs协程

## 进程线程区别
- 进程是程序执行的一个实例，是系统进行资源分配的最小单位，且每个进程拥有独立的地址空间；
- 线程是程序执行的基本单位，是轻量级的进程。每个进程中都有唯一的主线程
- 一个程序至少有一个进程，一个进程至少有一个线程；
- 创建他们的系统开销不同  
  - 因为进程拥有独立的堆栈空间和数据段，所以每当启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，系统开销比较大
  - 而线程不一样，线程拥有独立的堆栈空间，但是共享数据段，它们彼此之间使用相同的地址空间，共享大部分数据，切换速度也比进程快，效率高，
- 通信机制上面
  - 进程之间互不干扰，相互独立，进程的通信机制相对很复杂，譬如管道，信号，消息队列，共享内存，套接字等通信机制
  - 线程由于共享数据段所以通信机制很方便。。
- 属于同一个进程的所有线程共享该进程的所有资源，包括文件描述符。而不同过的进程相互独立。
- 安全性
  - 由于进程之间独立的特点，使得进程安全性比较高，也因为进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，
  - 而线程只是一个进程中的不同执行路径。一个线程死掉就等于整个进程死掉。

- 进程之间相互独立（资源的独立），而某一进程的各线程间共享资源（如果不能共享，岂不就与进程没多大区别了）；
- 由于进程的独立性，当进程间要相互通信时，系统只能提供各种外部方法，比较繁琐，而线程间的通信可以通过共享数据来实现；
- 线程的状态切换比进程更快捷且开销更小；
- 在多线程系统中，线程才是可执行对象，因为线程是进程中的并发任务的一种抽象。原先，进程是运行任务的主体，有了线程之后，运行任务的重担就落到了线程身上。

### 进程和线程的选择

- 需要频繁创建销毁的优先使用线程；因为对进程来说创建和销毁一个进程代价是很大的。
- 线程的切换速度快，所以在需要大量计算，切换频繁时用线程，还有耗时的操作使用线程可提高应用程序的响应
- 多线程模型主要优势为线程间切换代价较小，因此适用于I/O密集型的工作场景，因为I/O密集型的工作场景经常会由于I/O阻塞导致频繁的切换线程
- 因为对CPU系统的效率使用上线程更占优，所以可能要发展到多机分布的用进程，多核分布用线程；
- 并行操作时使用线程，如C/S架构的服务器端并发线程响应用户的请求；
- 需要更稳定安全时，适合选择进程；需要速度时，选择线程更好。




## 有了进程，为什么还要有线程

- 创建进程开销大
  - 调用 fork() 来创建进程的代价相对较高，即便利用写时复制技术，仍然需要复制诸如内存页表和文件描述符表之类的多种进程属性，这意味着 fork() 调用在时间上的开销依然不菲。
  - 但创建线程比创建进程通常要快 10 倍甚至更多。线程间是共享虚拟地址空间的，无需采用写时复制来复制内存，也无需复制页表
- 进程切换开销大
  - 进程频繁切换将引起额外开销，从而严重影响系统的性能。为了减少进程切换的开销，人们把两个任务放到一个进程中，每个任务用一个更小粒度的执行单元来实现并发执行，这就是线程。
- 进程间的信息难以共享
  - 由于除去只读代码段外，父子进程并未共享内存，因此必须采用一些进程间通信方式，在进程间进行信息交换。
  - 多个线程共享进程的内存，如代码段、数据段、扩展段，线程间进行信息交换十分方便。

## 协程
- 是一种比线程更加轻量级的存在。正如一个进程可以拥有多个线程一样，一个线程可以拥有多个协程
- 协程不是被操作系统内核管理，而完全是由程序所控制。
- 协程的开销远远小于线程；
- 协程拥有自己寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切换回来的时候，恢复先前保存的寄存器上下文和栈。
- 每个协程表示一个执行单元，有自己的本地数据，与其他协程共享全局数据和其他资源。
- 跨平台、跨体系架构、无需线程上下文切换的开销、方便切换控制流，简化编程模型；
- 协程又称为微线程，协程的完成主要靠yeild关键字，协程执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行；
- 协程极高的执行效率，和多线程相比，线程数量越多，协程的性能优势就越明显；
- 不需要多线程的锁机制；

--------------------------------------------------------------------------------------------------------------------------------------------

# 死锁

- 死锁是多个进程在执行过程中，因争夺资源而造成的相互等待的现象。

## 可抢占资源和不可抢占资源
- 可抢占资源(preemptable resource) 
  - 可以从拥有它的进程中抢占而不会造成其他影响
  - 内存就是一种可抢占性资源，任何进程都能够抢先获得内存的使用权。
- 不可抢占资源(nonpreemtable resource) 
  - 指的是除非引起错误或者异常，否则进程无法抢占指定资源
- 死锁与不可抢占资源有关

## 产生原因

- 互斥条件：每个资源都被分配给了一个进程或者资源是可用的
- 保持和等待条件：已经得到了某个资源的进程可以再请求新的资源
- 不可抢占条件：分配给一个进程的资源不能强制的从其他进程抢占资源，它只能由占有它的进程显示释放
- 循环等待：死锁发生时，系统中一定有两个或者两个以上的进程组成一个循环，循环中的每个进程都在等待下一个进程释放的资源

## 解决方法
- 鸵鸟策略
  - 忽略死锁带来的影响
  - 因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。
  - 当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。
  - 大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。
- 死锁检测与死锁恢复
  - 不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。
  - 死锁检测方法
    - 资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。
    - 通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生
  - 利用抢占恢复
    - 临时将某个资源从它的持有者转移到另一个进程
    - 比较困难而且有些简单粗暴，并不可取。
  - 利用回滚恢复
  - 通过杀死进程恢复
- 死锁预防
  - 资源一次性分配，从而剥夺请求和保持条件 
  - 可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件 
  - 资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件 
- 死锁避免
  - 在程序运行时避免发生死锁。
  - 银行家算法

## 死锁避免方法

- 银行家算法
  - 对每个请求进行检查，检查是否请求会引起不安全状态，如果不会引起，那么就接受该请求；如果会引起，那么就推迟该请求。
---------------------------------------

# 内存管理

## 物理内存四个层次

寄存器、高速缓存、主存、磁盘


## 内存管理需要满足的需求

- 重定位
  - 进程多次在内存切入切出，放置于不同位置能力 
  - 一旦程序被换出到磁盘，当下一次换入时，如果必须放在和被换出前相同的内存区域，那么这将会是很大的限制。为了避免这种限制，需要把进程重定位到内存的不同区域。 
- 保护
  - 保护进程的程序和数据不被未授权的进程访问和修改
  - 内存保护的需求必须有处理器硬件来满足，而不是操作系统（软件）来满足。这是因为操作系统不能够预测程序可能产生的所有的内存访问;即使可以预测，提前审查每个进程可能潜在的违法访问也是非常费时的，因此，只能在指令访问内存时来判断这个内存访问是否违法(存取数据或跳转)。为实现这一点，要求处理器有这个能力。 
- 共享
  - 多个进程访问内存同一区域 
  - 如果多个进程在执行同一个程序，则允许每个进程访问该程序的同一个副本比每个进程都有自己的单独的副本更有优势
- 逻辑组织
  - 把线性的地址空间组织成不同的模块
  - 可以独立编写和编译模块，系统在运行时解析一个模块到其他模块的所有引用。 
  - 通过适度的额外开销，可以给不同的模块以不同的保护级别（只读、只执行）。 
  - 可以引入某种机制，使得模块被多个进程共享。
- 物理组织
  - 两级存储
  - 内存提供快速的访问，成本高，并且内存是易失性的，不能提供永久存储。用于保存当前使用的程序或数据
  - 外存比内存慢且便宜，通常为非易失性的，用于长期存储程序和数据
  - 需要管理内存和磁盘间的信息流动

操作系统负责内存空间的分配与回收。
操作系统需要提供某种技术从逻辑上对内存空间进行扩充。
操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。
操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰


## 地址空间

- 要使多个应用程序同时处于内存中并且不互相影响，需要解决两个问题：保护和重定位
- 操作系统为每个进程提供了独占系统内存的假象
- 地址空间是一个进程可用于寻址内存的一套地址集合。每个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间


##  连续分配存储管理方式

连续分配是指为一个用户程序分配连续的内存空间。

### 单一连续存储管理
- 整个内存里面只有两个程序：一个是用户程序，另外一个是操作系统。
- 应用程序装入到用户区，可使用用户区全部空间，并且总是加载到同一个内存地址上。即用户程序永远从同一个地方开始执行。
- 优点：管理非常简单，实际上不需要任何的内存管理单元，程序运行速度快，因为越过了地址翻译这个步骤
- 缺点：
  - 整个程序要加载到内存空间中去，这样将导致比物理内存大的程序无法运行。
  - 只运行一个程序造成资源浪费，如果一个程序很小，虽然占用内存空间小，但剩下的内存空间也无法使用
  - 可能无法在不同的操作系统下运行，因为不同操作系统所占用的内存空间大小可能不一样，使得用户程序的起始地址可能不一样

### 分区式存储管理
- 把内存分为一些大小相等或不等的分区，操作系统占用其中一个分区，其余的分区由应用程序使用，每个应用程序占用一个或几个分区
- 可以支持并发，但难以进行内存分区的共享。
- 内碎片是占用分区内未被利用的空间
- 外碎片是占用分区之间难以利用的空闲分区(通常是小空闲分区)。
- 为实现分区式存储管理，操作系统应维护的数据结构为分区表或分区链表。表中各表项一般包括每个分区的起始地址、大小及状态(是否已分配)。
- 固定分区(nxedpartitioning)
  - 把内存划分为若干个固定大小的连续分区。
  - 分区大小可以相等：这种作法只适合于多个相同程序的并发执行(处理多个类型相同的对象)。
  - 分区大小也可以不等：有多个小分区、适量的中等分区以及少量的大分区。根据程序的大小，分配当前空闲的、适当大小的分区。
  - 优点：易于实现，开销小。
  - 缺点主要有两个：内碎片造成浪费；分区总数固定，限制了并发执行的程序数目。
- 动态分区(dynamic partitioning)
  - 动态创建分区：在装入程序时按其初始要求分配，或在其执行过程中通过系统调用进行分配或改变分区大小
  - 没有内碎片。但它却引入了另一种碎片——外碎片。
  - 寻找某个空闲分区，其大小需大于或等于程序的要求。若是大于要求，则将该分区分割成两个分区，其中一个分区为要求的大小并标记为“占用”，而另一个分区为余下部分并标记为“空闲”。分区释放过程中会将相邻的空闲分区合并成一个大的空闲分区
  - 常用的分区分配算法
    - 最先适配法(first-fit)：按分区在内存的先后次序从头查找，找到符合要求的第一个分区进行分配。该算法的分配和释放的时间性能较好，较大的空闲分区可以被保留在内存高端。但随着低端分区不断划分会产生较多小分区，每次分配时查找时间开销便会增大。
    - 下次适配法(循环首次适应算法 next fit)：按分区在内存的先后次序，从上次分配的分区起查找(到最后一个分区时再从头开始}，找到符合要求的第一个分区进行分配。该算法的分配和释放的时间性能较好，使空闲分区分布得更均匀，但较大空闲分区不易保留。
    - 最佳适配法(best-fit)：按分区在内存的先后次序从头查找，找到其大小与要求相差最小的空闲分区进行分配。从个别来看，外碎片较小；但从整体来看，会形成较多外碎片。优点是较大的空闲分区可以被保留。
    - 最坏适配法(worst- fit)：按分区在内存的先后次序从头查找，找到最大的空闲分区进行分配。基本不留下小空闲分区，不易形成外碎片。但由于较大的空闲分区不被保留，当对内存需求较大的进程需要运行时，其要求不易被满足。
- 伙伴系统
  - 固定分区和动态分区方式都有不足之处。
  - 固定分区方式限制了活动进程的数目，当进程大小与空闲分区大小不匹配时，内存空间利用率很低。
  - 动态分区方式算法复杂，回收空闲分区时需要进行分区合并等，系统开销较大。
  - 伙伴系统方式是对以上两种内存方式的一种折衷方案
    - 无论已分配分区或空闲分区，其大小均为 2 的 k 次幂，k 为整数， l≤k≤m，其中：
    - 2^l 表示分配的最小分区的大小，
    - 2^m 表示分配的最大分区的大小，2^m是整个可分配内存的大小。
    - 在系统运行过中，由于不断的划分，可能会形成若干个不连续的空闲分区，将这些空闲分区根据分区的大小进行分类，对于每一类具有相同大小的所有空闲分区，单独设立一个空闲分区双向链表。这样，不同大小的空闲分区形成了k(0≤k≤m)个空闲分区链表。  
    - 分配步骤
      - 当需要为进程分配一个长度为n 的存储空间时: 首先计算一个i 值，使 2^(i－1) < n ≤ 2^i，
      - 然后在空闲分区大小为2^i的空闲分区链表中查找。
      - 若找到，即把该空闲分区分配给进程。否则，表明长度为2^i的空闲分区已经耗尽，则在分区大小为2^(i＋1)的空闲分区链表中寻找。
      - 若存在 2^(i＋1)的一个空闲分区，则把该空闲分区分为相等的两个分区，这两个分区称为一对伙伴，其中的一个分区用于配，而把另一个加入分区大小为2^i的空闲分区链表中.若仍然找不到，则继续查找大小为 2^(i＋2)的空闲分区，以此类推。
    - 与一次分配可能要进行多次分割一样，一次回收也可能要进行多次合并，
- 内存紧缩
  - 将各个占用分区向内存一端移动，然后将各个空闲分区合并成为一个空闲分区。
  - 紧缩时机：每个分区释放后，或内存分配找不到满足条件的空闲分区时

### 空闲内存管理

- 位图
  - 内存可能被划分为小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0 表示空闲， 1 表示占用
  - 当决定为把具有 k 个分配单元的进程放入内存时，内容管理器(memory manager) 必须搜索位图，在位图中找出能够运行 k 个连续 0 位的串
- 链表
  - 

## 覆盖和交换技术
- 覆盖
  - 引入覆盖 (overlay)技术的目标是在较小的可用内存中运行较大的程序。这种技术常用于多道程序系统之中，与分区式存储管理配合使用
  - 原理
    - 程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成为一个固定区和若干个覆盖区
    - 将程序必要部分和经常活跃的部分放在固定区；
    - 可选部分(不常用功能)平时存放在外存(覆盖文件)中，在需要时才装入内存。不存在调用关系的模块不必同时装入到内存，从而可以相互覆盖。
    - 在任何时候只在内存中保留所需的指令和数据；当需要其它指令时，它们会装入到刚刚不再需要的指令所占用的内存空间；
  - 缺点
    - 编程时必须划分程序模块和确定程序模块之间的覆盖关系，增加编程复杂度；
    - 从外存装入覆盖文件，以时间延长换取空间节省
- 交换
  - 在多个程序并发执行时，可以将暂时不能执行的进程送到外存中，从而获得空闲内存空间来装入新进程，或读入保存在外存中而处于就绪状态的进程
  - 交换单位为整个进程的地址空间
  - 交换技术优点之一是增加并发运行的程序数目，并给用户提供适当的响应时间；与覆盖技术相比交换技术另一个显著的优点是不影响程序结构。
  - 对换人和换出的控制增加处理器开销；程序整个地址空间都进行对换，没有考虑执行过程中地址访问的统计特性。
- 两者对比
  - 与覆盖技术相比，交换不要求程序员给出程序段之间的覆盖结构。
  - 交换主要是在进程与作业之间进行，而覆盖则主要在同一作业或进程内进行。 另外覆盖只能覆盖那些与覆盖程序段无关的程序段。
  - 交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一程序或进程中


## 内存交换中，被换出的进程保存在哪里？

- 保存在磁盘中，也就是外存中。
- 具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。
  - 文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式;
  - 对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。
    - 由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式(学过文件管理章节后即可理解)。总之，对换区的I/O速度比文件区的更快。

# 虚拟内存

## 内存

- 内存就是用于存放数据的硬件
- 程序执行前需要先放入内存中才能被CPU处理

## 什么是虚拟内存

- 虚拟内存本质上是用来创造一个地址空间的抽象
- 让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存
- 操作系统将内存抽象成地址空间,每个程序都拥有自己的地址空间，被分解成页，并将每一项映射到物理内存的某个页框。
- 这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。
- 在使用虚拟内存时，虚拟地址不会直接发送到内存总线上。相反会使用 MMU(Memory Management Unit) 内存管理单元把虚拟地址映射为物理内存地址

## 虚拟内存的好处和代价
- 好处
  - 扩大地址空间； 
  - 内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。 
  - 公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。 
  - 当进程通信时，可采用虚存共享的方式实现。 
  - 当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存 
  - 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高 
  - 在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片 
- 代价 
  - 虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存 
  - 虚拟地址到物理地址的转换，增加了指令的执行时间。 
  - 页面的换入换出需要磁盘I/O，这是很耗时的 
  - 如果一页中只有一部分数据，会浪费内存

## 分页技术

- 虚拟地址空间由固定大小的单元组成，这种固定大小的单元称为页(pages)。
- 物理内存中也有固定大小的物理单元，称为页框(page frames)。
- 页和页框的大小一样，RAM 和磁盘之间的交换总是以整个页为单元进行交换的
- 页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表
- 缺页中断

### MMU的工作原理

- Memory Management Unit, 内存管理单元
  - 虚拟地址与物理地址的转换
  - 访问权限控制
- 一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量
- 例如：输入的 16 位虚拟地址被分为 4 位的页号和 12 位的偏移量。
  - 4 位的页号可以表示 16 个页面，12 位的偏移可以为一页内的全部 4096 个字节。
- 可用页号作为页表(page table) 的索引，以得出对应于该虚拟页面的页框号
- 将在页表中查到的页框号复制到输出寄存器的高 3 位中，再加上输入虚拟地址中的低 12 位偏移量。如此就构成了 15 位的物理地址
- 把页框号拼接到偏移量的高位端，替代虚拟页号，形成物理地址

### 页表

- Page Table Entry(PTE)
- 页表的目的是把虚拟页映射到页框中。从数学上说，页表是一个函数，它的参数是虚拟页号，结果是物理页框号
- 页表项的结构
  - 页框号(Page frame number)。毕竟，页表到页框最重要的一步操作就是要把此值映射过去
  - 在/不在位
    - 由于进程某些页可能不在内存中，所以页表项中有一位表示该页是否在内存中
    - 如果此位上的值是 1，那么页表项是有效的并且能够被使用。
    - 如果此值是 0 的话，则表示该页表项对应的虚拟页面不在内存中，访问该页面会引起一个缺页异常(page fault)。
  - 保护位(Protection) 
    - 0 表示可读可写，1 表示的是只读。
  - 修改位(Modified) 和 访问位(Referenced)
    - 当一个页面被写入时，硬件会自动的设置修改位
    - 访问位(Referenced) 在页面被访问时被设置，不管是读还是写
    - 如果一个页面已经被修改过（即它是 脏 的），则必须把它写回磁盘。如果一个页面没有被修改过（即它是 干净的），那么重新分配时这个页框会被直接丢弃，因为磁盘上的副本仍然是有效的。这个位有时也叫做 脏位(dirty bit)，因为它反映了页面的状态
     - 在页面置换算法中作用也很大。
  - 高速缓存禁止位

### 分页系统的问题

- 虚拟地址到物理地址的映射速度必须要快
  - 由于每次访问内存都需要进行虚拟地址到物理地址的映射
  - 用TLB解决
- 如果虚拟地址空间足够大，那么页表也会足够大
  - 假设页大小为 4 KB，32 位的地址空间将近有 100 万页，而 64 位地址空间简直多到无法想象。
  - 用多级页表
  - 用倒排页表
- 如果把进程页表读副本放入寄存器中
  - 简单而且映射过程中不需要访问内存。
  - 缺点是 页表太大时，代价高昂，而且每次上下文切换的时候都必须装载整个页表，这样会造成性能的降低

### 转换检测缓冲区(Translation Lookaside Buffer, TLB)，快表

- 使用的原因
  - 原则上，每次虚拟内存访问可能引起两次物理内存访问：一次取相应的页表项，一次取需要的数据。因此，简单的虚拟内存方案会导致内存访问时间加倍
  - 大多数程序总是对少量页面进行多次访问，而不是对大量页面进行少量访问。因此，只有很少的页面能够被再次访问，而其他的页表项很少被访问
- 转换检测缓冲区(Translation Lookaside Buffer, TLB）
  - 用于虚拟地址到物理地址的映射速度必须要快的问题
  - 一种访问速度比内存快很多的高速缓冲存储器，用来存放当前访问的若干页表项，以加速地址变换的过程
  - 一个小型的硬件设备，能够将虚拟地址直接映射到物理地址，而不必再访问页表
  - 通常位于 MMU 中，包含少量的表项，每个表项都记录了页面的相关信息（虚拟页号，保护位，有效位，修改位，页框号）
- 工作流程
  - 当一个 MMU 中的虚拟地址需要进行转换时，硬件首先检查虚拟页号与 TLB 中所有表项进行并行匹配，判断虚拟页是否在 TLB 中
  - 如果找到了有效匹配项，并且要进行的访问操作没有违反保护位的话，则将页框号直接从 TLB 中取出而不用再直接访问页表
  - 如果虚拟页在 TLB 中但是违反了保护位的权限的话（比如只允许读但是是一个写指令），则会生成一个保护错误(protection fault) 返回
  - 如果 MMU 检测到没有有效的匹配项，就会进行正常的页表查找
  - 如果”存在位“置位，则页在内存中，处理器从页表项中检索页框号形成实地址。并更新TLB
  - 如果”存在位”没置位，表示需要的页不在内存中，这时发生**缺页中断**，因此离开硬件作用范围，调用操作系统，操作系统负责载入所需要的页，并更新页表
- 快表命中只需访问一次内存，未命中需要访问两次内存

### 多级页表

- 解决页表太多的问题，避免把全部页表一直保存在内存中。不需要的页表就不应该保留
- 由两个或多个层次的分页表组成，也称为分层分页。
  - 级别1（level 1）页表的条目是指向级别 2（level 2） 页表的指针
  - 级别2页面表的条目是指向级别 3（level 3） 页面表的指针
  - 最后一级页表存储的是实际的信息。

### 倒排页表

- 物理内存中的每个页框对应一个表项，而不是每个虚拟页面对应一个表项。
- 那就是从虚拟地址到物理地址的转换会变得很困难
  - 当进程 n 访问虚拟页面 p 时，硬件不能再通过把 p 当作指向页表的一个索引来查找物理页。而是必须搜索整个倒排表来查找某个表项。
  - 另外，搜索必须对每一个内存访问操作都执行一次，而不是在发生缺页中断时执行。
- 解决方法
  - 使用 TLB。只有当发生 TLB 失效时，需要用软件搜索整个倒排页表
  - 建立一个散列表，用虚拟地址来散列。当前所有内存中的具有相同散列值的虚拟页面被链接在一起


## 缺页中断

- 在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。
- 与一般的中断存在区别：
  - 在指令执行期间产生和处理缺页中断信号
  - 一条指令在执行期间，可能产生多次缺页中断
  - 缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。

### 缺页置换方法
- 当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。
- **最优页面置换算法**
  - 把最晚被用上的页置换出去
  - 很容易描述但在实际情况下很难实现，因为无法知道一个页面多长时间不再被访问
- **最近未使用NRU** (Not Recently Used）
  - 每当引用页面（读入或写入）时都设置 R（访问位），写入（即修改）页面时设置 M（修改位）
  - 当出现缺页中断后，操作系统会检查所有的页面，并根据它们的 R 位和 M 位将当前值分为四类：
    - 第 0 类：没有引用 R，没有修改 M
    - 第 1 类：没有引用 R，已修改 M
    - 第 2 类：引用 R ，没有修改 M
    - 第 3 类：已被访问 R，已被修改 M
  - 从编号最小的非空类中随机删除一个页面。
  - 在一个时钟内（约 20 ms）淘汰一个已修改但是没有被访问的页面要比一个大量引用的未修改页面好
  - NRU 的主要优点是易于理解并且能够有效的实现。
- **先进先出FIFO**
  - 置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。
  - 维护一个所有在当前内存中的页面的链表，从队尾进入，从队首删除。 
  - **第二次机会页面置换算法**
    - FIFO 链表页面有个缺陷，那就是出链和入链并不会进行 check 检查，这样就会容易把经常使用的页面置换出去
    - 我们检查最老页面的 R 位，如果是 0 ，那么这个页面就是最老的而且没有被使用，那么这个页面就会被立刻换出。
    - 如果 R 位是 1，那么就清除此位，随后此页面会被放在链表的尾部
  - **时钟页面置换算法**
    - 第二次页面置换算法经常要在链表中移动页面，既降低了效率
    - 把所有的页面都保存在一个类似钟面的环形链表中，一个表针指向最老的页面
    - 当缺页错误出现时，算法首先检查表针指向的页面，如果它的 R 位是 0 就淘汰该页面，并把新的页面插入到这个位置，然后把表针向前移动一位；如果 R 位是 1 就清除 R 位并把表针前移一个位置。重复这个过程直到找到了一个 R 位为 0 的页面位置
- **最近最少使用(LRU)** Least Recently Used
  - 置换最近一段时间以来最长时间未访问过的页面。
  - 根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。 
  - 为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。
  - 缓存颠簸，当缓存（1，2，3）满了，之后数据访问（0，3，2，1，0，3，2，1。。。）。
    - 进程频繁访问的页面数目高于可用的物理块数 
  - 缓存污染，突然大量偶发性的数据访问，会让内存中存放大量冷数据。 
- **最少使用LFU**Not Frequently Used，最不常用
  - 如果数据过去被访问多次，那么将来被访问的频率也更高。 
  - 一个软件计数器来和每个页面关联，初始化的时候是 0 。在每个时钟中断时，操作系统会浏览内存中的所有页，会将每个页面的 R 位（0 或 1）加到它的计数器上
  - 当缺页异常出现时，则置换计数器值最小的页面
  - LFU 最主要的问题是它不会忘记任何东西
  - 老化算法，模拟LRU
    - 首先，在 R 位被添加进来之前先把计数器右移一位；
    - 第二步，R 位被添加到最左边的位而不是最右边的位
- **LRU-K**（LRU-2、LRU-3） 
  - 最久未使用K次淘汰算法。
  - 将“最近使用过1次”的判断标准扩展为“最近使用过K次”。
  - LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。 
- 工作集页面置换算法
  - 一个进程当前正在使用的页面的集合称为它的 工作集(working set)
- 工作集时钟页面置换算法

### LRU的实现

- 利用链表和hashmap。
- 当需要插入新的数据项的时候，如果新数据命中，则把该节点放到链表头部，如果不存在，则将新数据放在链表头部。若缓存满了，则将链表尾部的节点删除。
```cpp
class myListNode
{
public:
    myListNode(int k, int v) : key(k), val(v), pre(nullptr), next(nullptr) {}
    int key;
    int val;
    myListNode *pre;
    myListNode *next;
};

class myList
{
public:
    myList() : head(nullptr), tail(nullptr) {}
    myListNode *get_head()
    {
        return head;
    }
    myListNode *get_back()
    {
        return tail;
    }
    void move_head(myListNode *node)
    {
        if (node == head)
            return;
        node->pre->next = node->next;
        if (node->next)
            node->next->pre = node->pre;
        else
            tail = node->pre;
        push_head(node);
    }
    void push_head(int k, int v)
    {
        myListNode *newnode = new myListNode(k, v);
        push_head(newnode);
    }
    void push_head(myListNode *node)
    {
        if (!head)
        {
            head = node;
            tail = node;
        }
        else
        {
            node->next = head;
            head->pre = node;
            head = node;
        }
    }
    void pop_back()
    {
        if (head == tail)
        {
            delete head;
            head = tail = nullptr;
        }
        else
        {
            myListNode *tem = tail;
            tail->pre->next = nullptr;
            tail = tail->pre;
            delete tem;
        }
    }
    myListNode *head;
    myListNode *tail;
};

class LRUCache
{
public:
    LRUCache(int capacity) : size(0), maxsize(capacity)
    {
    }

    int get(int key)
    {
        if (map_.count(key))
        {
            list_.move_head(map_[key]);
            return map_[key]->val;
        }
        else
            return -1;
    }

    void put(int key, int value)
    {
        if (map_.count(key))
        {
            map_[key]->val=value;
            list_.move_head(map_[key]);
        }
        else
        {
            list_.push_head(key, value);
            map_[key] = list_.get_head();
            ++size;
            if (size > maxsize)
            {
                myListNode *del = list_.get_back();
                map_.erase(del->key);
                list_.pop_back();
                --size;
            }
        }
    }

private:
    unordered_map<int, myListNode *> map_;
    myList list_;
    int size;
    int maxsize;
};
```


### LRU-K的实现

相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据

## 分段技术

- 每个进程的地址空间按照自身的逻辑划分为若干段，每个段都有一个唯一的内部段号。
- 每个段的长度可以不同，并且可以动态增长
- 逻辑地址由段号S与段内偏移量W两部分组成。

### 段页式存储管理
- 在段页式存储中，每个分段又被分成若干个固定大小的页。
- 一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长
- 逻辑地址由段号S、段内页号P与页内偏移量W两部分组成。

### 段页式管理每一次数据要访问几次内存? 
- 三次
- 第一次是由段表地址寄存器得段表始址后访问段表，由此取出对应段的页表在内存中的地址。 第二次则是访问页表得到所要访问的物理地址。 第三次才能访问真正需要访问的物理单元。

### 页和段的区别

- 页是信息的物理单位，分页是由于系统管理的需要。段是信息的逻辑单位，分段是为了满足用户的要求。
- 页的大小固定且由系统决定，段的长度不固定，决定于用户所编写的程序，通常由编译程序在对源程序紧进行编译时，根据信息的性质来划分。
- 分页的作业的地址空间是一维的，程序员只需要利用一个记忆符，即可表示一个地址。分段的作业地址空间则是二维的，程序员在标识一个地址时，既需要给出段名，又需要给出段的地址值。
- 分页有内部碎片无外部碎片，分段有外部碎片无内部碎片
- 出现的原因
  - 分页主要用于实现虚拟内存，从而获得更大的地址空间；
  - 分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

### 内部碎片和外部碎片
- 内碎片
  - 分配给某些进程的内存区域中有些部分没用上，常见于固定分配方式
  - 固定分配，将100M分割成10块，每块10M，一个程序需要45M，那么需要分配5块，第五块只用了5M，剩下的5M就是内部碎片
- 外碎片
  - 内存中某些空闲区因为比较小，而难以利用上，一般出现在内存动态分配方式中
- 分段式存储管理有外部碎片而无内部碎片？为什么固定分区分配有内部碎片而不会有外部碎片
- 对于内部碎片，通过紧凑技术消除，就是操作系统不时地对进程进行移动和整理。但是这需要动态重定位寄存器地支持，且相对费时
- 解决外部内存碎片的问题就是内存交换



## 内存溢出和内存泄漏
* 内存溢出 
   * 指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实际分配给你的空间，此时系统相当于没法满足你的需求，就会报内存溢出的错误 
   * 内存溢出原因： 
      * 内存中加载的数据量过于庞大，如一次从数据库取出过多数据 
      * 集合类中有对对象的引用，使用完后未清空，使得不能回收 
      * 代码中存在死循环或循环产生过多重复的对象实体 
      * 使用的第三方软件中的BUG 
      * 启动参数内存值设定的过小 
* 内存泄漏 
   * 内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。  
   * 堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。 
   * 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。
   * 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。 
---------------------------------------------------

# IO

### 标准io和文件io的区别

* 不带缓冲的IO函数都是围绕文件描述符进行的
* 对于带缓冲的标准IO函数，操作是围绕流进行的
  
不带缓冲的IO指的是这一章节介绍的读写操作都只是内核中的一个系统调用  
不带缓冲，并不是指内核不提供缓冲，而是只单纯的系统调用，不是函数库的调用。系统内核对磁盘的读写都会提供一个块缓冲（在有些地方也被称为内核高速缓存），当用write函数对其写数据时，直接调用系统调用，将数据写入到块缓冲进行排队，当块缓冲达到一定的量时，才会把数据写入磁盘。因此所谓的不带缓冲的I/O是指进程不提供缓冲功能（但内核还是提供缓冲的）。每调用一次write或read函数，直接系统调用。  
而带缓冲的I/O是指进程对输入输出流进行了改进，提供了一个流缓冲，当用fwrite函数网磁盘写数据时，先把数据写入流缓冲区中，当达到一定条件，比如流缓冲区满了，或刷新流缓冲，这时候才会把数据一次送往内核提供的块缓冲，再经块缓冲写入磁盘。（双重缓冲）  
因此，带缓冲的I/O在往磁盘写入相同的数据量时，会比不带缓冲的I/O调用系统调用的次数要少。  

- 无缓存IO操作数据流向路径：数据——内核缓存区——磁盘
- 标准IO操作数据流向路径：数据——流缓存区——内核缓存区——磁盘

# 信号

- 进程可以选择忽略发送过来的信号，但是有两个是不能忽略的：SIGSTOP 和 SIGKILL 信号。SIGSTOP 信号会通知当前正在运行的进程执行关闭操作，SIGKILL 信号会通知当前进程应该被杀死
- 除此之外，进程可以选择它想要处理的信号，进程也可以选择阻止信号，如果不阻止，可以选择自行处理，也可以选择进行内核处理。如果选择交给内核进行处理，那么就执行默认处理。
## 常见的信号