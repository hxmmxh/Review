

第二家面试的是TPLINK，自我介绍，介绍项目经历，在一亿条URL里面查找出现次数最多的URL，讲一讲查找算法，排序算法，只记得这些了，答得不好，感觉自己像个菜鸡。后来居然接到了二面通知，二面围绕项目经历，还可以，就是最后没问我期望薪资，我其他同学说人家都问他的，以为自己又挂了。最后还是接到了录用通知，深圳13*16，offer2 get ！ 





tplink 云计算开发一面：
1.链表判断环，我说哈希表或者快慢指针，面试官问快指针每次移动三次可以吗，想了半天。。
2.哈夫曼编码 
3.介绍项目
4.介绍快排
5.笔试时的一道题的时间复杂度（找子递增序列）
     我的tp一面就是聊天感觉，没有问什么。。 同学的tplink一面：
1.进程线程
2.os中断 
3.编译和链接的区别 
4.malloc和new的区别 
5.变量存储位置 
6.tcp/udp区别 
7.tcp为什么可靠 
tplink二面： 
1.实现程序求cos余弦值，只给出角度，求出小数点后四位，要求性能尽量好（写不出来，面试官提示用泰勒展开式。。嗯。。。。） 
2.printf("%08s",a); 我说不熟c语言，面试官那用c++，cout<<hex<<a;（想了半天hex是16进制还是8进制，然后当成8进制来说，然后就说错了） 
3.怎么找字符串（忘了状态机） 
4.信息论加密原理（不知道他问的是不是密码学，这么问我就还是没答上来。。） 
四个问题瞬间爆炸，我已经将tplink在纸上划掉了，没想到后面居然过了。。听说加班不严重，当时又没保底的，今年这个形势实在不敢像秋招那样浪了，就签了他们的大白菜。。。




## 笔试内容
* 大数据专题
* 最长回文子序列
```
状态
f[i][j] 表示 s 的第 i 个字符到第 j 个字符组成的子串中，最长的回文序列长度是多少。


转移方程
如果 s 的第 i 个字符和第 j 个字符相同的话
f[i][j] = f[i + 1][j - 1] + 2
如果 s 的第 i 个字符和第 j 个字符不同的话
f[i][j] = max(f[i + 1][j], f[i][j - 1])
然后注意遍历顺序，i 从最后一个字符开始往前遍历，j 从 i + 1 开始往后遍历，这样可以保证每个子问题都已经算好了。


初始化
f[i][i] = 1 单个字符的最长回文序列是 1


结果
f[0][n - 1]

```
* 最长回文子串
```
动态规划
我们给出 P(i,j) 的定义如下：

P(i,j)=true​如果子串Si​…Sj​是回文子串,其它情况​则为false

因此，
P(i,j)=P(i+1,j−1) && Si==Sj

基本示例如下：

P(i,i)=true
P(i,i+1)= (Si​==Si+1​)
这产生了一个直观的动态规划解法，我们首先初始化一字母和二字母的回文，然后找到所有三字母回文，并依此类推…

```
```
中心扩展算法
事实上，只需使用恒定的空间，我们就可以O(n^2)的时间内解决这个问题。
我们观察到回文中心的两侧互为镜像。因此，回文可以从它的中心展开，并且只有 2n−1个这样的中心。
你可能会问，为什么会是 2n−1个，而不是 n个中心？原因在于所含字母数为偶数的回文的中心可以处于两字母之间（例如 “abba” 的中心在两个 ‘b’‘b’ 之间）
public String longestPalindrome(String s) {
    if (s == null || s.length() < 1) return "";
    int start = 0, end = 0;
    for (int i = 0; i < s.length(); i++) {
        int len1 = expandAroundCenter(s, i, i);
        int len2 = expandAroundCenter(s, i, i + 1);
        int len = Math.max(len1, len2);
        if (len > end - start) {
            start = i - (len - 1) / 2;
            end = i + len / 2;
        }
    }
    return s.substring(start, end + 1);
}

private int expandAroundCenter(String s, int left, int right) {
    int L = left, R = right;
    while (L >= 0 && R < s.length() && s.charAt(L) == s.charAt(R)) {
        L--;
        R++;
    }
    return R - L - 1;
}


```

### 马拉车算法
将时间复杂度提升到了线性。
解决单双两次遍历的问题
首先对字符串做一个预处理，在所有的空隙位置（包括首尾）插入同样的符号，要求这个符号是不会在原串中出现的。这样会使得所有的串都是奇数长度的，并且回文串的中心不会是双数，以插入#号为例：







## 外部排序
[参考资料](http://data.biancheng.net/memory/)
* 当待排序的文件比内存的可使用容量还大时，文件无法一次性放到内存中进行排序，需要借助于外部存储器（例如硬盘、U盘、光盘），这时就需要外部排序算法来解决。
* 外部排序算法由两个阶段构成：
    * 按照内存大小，将大文件分成若干长度为 l 的子文件（l 应小于内存的可使用容量），然后将各个子文件依次读入内存，使用适当的内部排序算法对其进行排序（排好序的子文件统称为“归并段”或者“顺段”），将排好序的归并段重新写入外存，为下一个子文件排序腾出内存空间；
    * 对得到的顺段进行合并，直至得到整个有序的文件为止。
* 影响整体排序效率的因素
    * 取决于读写外存的次数，即访问外存的次数越多，算法花费的时间就越多，效率就越低。
    * 对于同一个文件来说，对其进行外部排序时访问外存的次数同归并的次数成正比，即归并操作的次数越多，访问外存的次数就越多
    *  对于k-路平衡归并中 k 值得选择，增加 k 可以减少归并的次数，从而减少外存读写的次数，最终达到提高算法效率的目的
    * 一般情况下对于具有 m 个初始归并段进行 k-路平衡归并时，归并的次数为：s=⌊logk⁡m ⌋（其中 s 表示归并次数）。
* 想要达到减少归并次数从而提高算法效率的目的，可以从两个角度实现：
    * 增加 k-路平衡归并中的 k 值；多路平衡归并算法
    * 尽量减少初始归并段的数量 m，即增加每个归并段的容量；置换-选择排序算法

### 多路平衡归并排序算法
* 如果毫无限度地增加 k 值，虽然会减少读写外存数据的次数，但会增加内部归并的时间，得不偿失。
* 为了避免在增加 k 值的过程中影响内部归并的效率，在进行 k-路归并时可以使用“败者树”来实现，该方法在增加 k 值时不会影响其内部归并的效率
* 败者树
    * 败者树是树形选择排序的一种变形，本身是一棵完全二叉树。
    * “胜者树”。树中每个非终端结点（除叶子结点之外的其它结点）中的值都表示的是左右孩子相比较后的较小值（谁最小即为胜者）
    * 败者树恰好相反，其双亲结点存储的是左右孩子比较之后的失败者，而胜利者则继续同其它的胜者去比较
    * 胜者树和败者树的区别就是：胜者树中的非终端结点中存储的是胜利的一方；而败者树中的非终端结点存储的是失败的一方。而在比较过程中，都是拿胜者去比较。
    * 为了防止在归并过程中某个归并段变为空，处理的办法为：可以在每个归并段最后附加一个关键字为最大值的记录。这样当某一时刻选出的冠军为最大值时，表明所有归并段已全部归并完成。（因为只要还有记录，最终的胜者就不可能是附加的最大值
* 置换选择排序算法
    * m 的求值方法为：m=⌈n/l⌉（n 表示为外部文件中的记录数，l 表示初始归并段中包含的记录数）
    * 如果要想减小 m 的值，在外部文件总的记录数 n 值一定的情况下，只能增加每个归并段中所包含的记录数 l。而对于初始归并段的形成，就不能再采用内部排序的算法，因为所有的内部排序算法正常运行的前提是所有的记录都存在于内存中，而内存的可使用空间是一定的，如果增加 l 的值，内存是盛不下的。
    * 步骤
        * 首先从初始文件中输入n个记录到内存工作区中；
        * 从内存工作区中选出关键字最小的记录，将其记为 MINIMAX 记录；
        * 然后将 MINIMAX 记录输出到归并段文件中；
        * 此时内存工作区中还剩余n-1个记录，若初始文件不为空，则从初始文件中输入下一个记录到内存工作区中；
        * 从内存工作区中的所有比 MINIMAX 值大的记录中选出值最小的关键字的记录，作为新的 MINIMAX 记录；
        * 重复过程 3—5，直至在内存工作区中选不出新的 MINIMAX 记录为止，由此就得到了一个初始归并段；
        * 重复 2—6，直至内存工作为空，由此就可以得到全部的初始归并段。
    * 在上述创建初始段文件的过程中，需要不断地在内存工作区中选择新的 MINIMAX 记录，即选择不小于旧的 MINIMAX 记录的最小值，此过程需要利用“败者树”来实现。
        * 在不断选择新的 MINIMAX 记录时，为了防止新加入的关键字值小的的影响，每个叶子结点附加一个序号位，当进行关键字的比较时，先比较序号，序号小的为胜者；序号相同的关键字值小的为胜者。
        * 当读入新的记录时，如果其值比 MINIMAX 大，其序号则仍为 1；反之则为 2 ，比较时序号 1 比序号 2的记录大。
        * 通过不断地向败者树中读入记录，会产生多个 MINIMAX，直到最终所有叶子结点中的序号都为 2，此时产生的新的 MINIMAX 值的序号 2，表明此归并段生成完成，而此新的 MINIMAX 值就是下一个归并段中的第一个记录。
* 最佳归并树
    * 无论是通过等分还是置换-选择排序得到的归并段，如何设置它们的归并顺序，可以使得对外存的访问次数降到最低？
    * 对于如何减少访问外存的次数的问题，就等同于考虑如何使 k-路归并所构成的 k 叉树的带权路径长度最短。
    * 若想使树的带权路径长度最短，就是构造赫夫曼树。 
    * 在一般情况下，对于 k–路平衡归并来说，若 (m-1)MOD(k-1)=0，则不需要增加虚段；否则需附加 k-(m-1)MOD(k-1)-1 个虚段。 
    * 附加一个权值为 0 的结点（称为“虚段”），然后再构建赫夫曼树。

### 外部排序小结
* 外部排序的两个过程
    * 将整个初始文件分为多个初始归并段;
    * 将初始归并段进行归并，直至得到一个有序的完整文件；

* 为了提高整个外部排序的效率，可以两个方面对外部排序进行优化：
    * 在实现将初始文件分为 m 个初始归并段时，为了尽量减小 m 的值，采用置换-选择排序算法，可实现将整个初始文件分为数量较少的长度不等的初始归并段。
    * 同时在将初始归并段归并为有序完整文件的过程中，为了尽量减少读写外存的次数，采用构建最佳归并树的方式，对初始归并段进行归并，而归并的具体实现方法是采用败者树的方式。

## 完美洗牌算法
[参考资料](https://blog.csdn.net/juzihongle1/article/details/76563336)
对于2*n =（3^k-1）这种长度的数组，恰好只有k个环，且每个环的起始位置分别是1,3,9，…3^(k-1)



## KMP算法
* 字符串匹配
    * 朴素算法： 每次失配，S串的索引i定位的本次尝试匹配的第一个字符的后一个。P串的索引j定位到1；T(n)=O(n*m)
    * KMP算法： 每次失配，S串的索引i不动，P串的索引j定位到某个数。T(n)=O(n+m)，时间效率明显提高
* next[j]
    * next[j]就是第j个元素前j-1个元素首尾重合部分个数加一，当然，为了能遍历完整，首尾重合部分的元素个数应取到最多，即next[j]应取尽量大的值
* 字符串的前缀和后缀。
    * 如果字符串A和B，存在A=BS，其中S是任意的非空字符串，那就称B为A的前缀,把所有前缀组成的集合，称为字符串的前缀集合
    * 后缀A=SB， 其中S是任意的非空字符串，那就称B为A的后缀,把所有后缀组成的集合，称为字符串的后缀集合
    * PMT数组中的值是字符串的前缀集合与后缀集合的交集中最长元素的长度
    * 使用PMT加速字符串的查找了。我们看到如果是在 j 位 失配，那么影响 j 指针回溯的位置的其实是第 j −1 位的 PMT 值，所以为了编程的方便， 我们不直接使用PMT数组，而是将PMT数组向后偏移一位。我们把新得到的这个数组称为next数组
    * 在把PMT进行向右偏移时，第0位的值，我们将其设成了-1，这只是为了编程的方便，并没有其他的意义
* 求next数组的过程
    * 完全可以看成字符串匹配的过程，即以模式字符串为主字符串，以模式字符串的前缀为目标字符串，一旦字符串匹配成功，那么当前的next值就是匹配成功的字符串的长度。


## 100亿个整数，内存足够，如何找到中位数？内存不足，如何找到中位数？ 
 [参考资料](https://www.cnblogs.com/vincently/p/4817011.html)
* 内存足够的情况： 可以使⽤用类似quick sort的思想进行，均摊复杂度为O(n)，算法思想如下： 
    * 随机选取一个元素，将比它小的元素放在它左边，比它大的元素放在右边 
    * 如果它恰好在中位数的位置，那么它就是中位数，可以直接返回 
    * 如果小于它的数超过一半，那么中位数一定在左半边，递归到左边处理 
    * 否则，中位数一定在右半边，根据左半边的元素个数计算出中位数是右半边的第几大，然后递归到右半边处理 
* 内存不足的情况
    * 无重复数字：bitmap方法
    * 有重复数字：基于字节的桶排序是一个可行的方法 
        * 思想：将整形的每1byte作为一个关键字，也就是说一个整形可以拆成4个keys，而且最高位的keys越大，整数越大。如果高位keys相同，则比较次高位的keys。整个比较过程类似于字符串的字典序。
        * 第一步:把10G整数每2G读入一次内存，然后一次遍历这536,870,912个数据。每个数据用位运算">>"取出最高8位(31-24)。这8bits(0-255)最多表示255个桶，那么可以根据8bit的值来确定丢入第几个桶。最后把每个桶写入一个磁盘文件中，同时在内存中统计每个桶内数据的数量，自然这个数量只需要255个整形空间即可。
        * 代价：(1) 10G数据依次读入内存的IO代价(这个是无法避免的，CPU不能直接在磁盘上运算)。(2)在内存中遍历536,870,912个数据，这是一个O(n)的线性时间复杂度。(3)把255个桶写会到255个磁盘文件空间中，这个代价是额外的，也就是多付出一倍的10G数据转移的时间。 
        * 第二步：根据内存中255个桶内的数量，计算中位数在第几个桶中。很显然，2,684,354,560个数中位数是第1,342,177,280个。假设前127个桶的数据量相加，发现少于1,342,177,280，把第128个桶数据量加上，大于1,342,177,280。说明，中位数必在磁盘的第128个桶中。而且在这个桶的第1,342,177,280-N(0-127)个数位上。N(0-127)表示前127个桶的数据量之和。然后把第128个文件中的整数读入内存。(平均而言，每个文件的大小估计在10G/128=80M左右，当然也不一定，但是超过2G的可能性很小)。
        * 代价：(1)循环计算255个桶中的数据量累加，需要O(M)的代价，其中m<255。(2)读入一个大概80M左右文件大小的IO代价。 
        * 第三步：继续以内存中的整数的次高8bit进行桶排序(23-16)。过程和第一步相同，也是255个桶。
        * 第四步：一直下去，直到最低字节(7-0bit)的桶排序结束。我相信这个时候完全可以在内存中使用一次快排就可以了。
        * 整个过程的时间复杂度在O(n)的线性级别上(没有任何循环嵌套)。但主要时间消耗在第一步的第二次内存-磁盘数据交换上，即10G数据分255个文件写回磁盘上。一般而言，如果第二步过后，内存可以容纳下存在中位数的某一个文件的话，直接快排就可以了。