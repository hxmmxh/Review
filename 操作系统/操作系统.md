# 目录
   * [概述](#概述)
   * [进程与线程](#进程与线程)
   * [死锁](#死锁)
   * [内存管理](#内存管理)

----------------------------------------------------
# 概述

### 操作系统基本特征
1. 并发
   * 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。
   * 并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。
   * 操作系统通过引入进程和线程，使得程序能够并发运行。
   * 并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。 
   * 并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。 
2. 共享
   * 共享是指系统中的资源可以被多个并发进程共同使用。
   * 有两种共享方式：互斥共享和同时共享。
   * 互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。
3. 虚拟
   * 虚拟技术把一个物理实体转换为多个逻辑实体。主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。
   * 多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。
   * 虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。
4. 异步
   * 异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。

### 操作系统基本功能
1. 进程管理  
进程控制、进程同步、进程通信、死锁处理、处理机调度等。
2. 内存管理  
内存分配、地址映射、内存保护与共享、虚拟内存等。
3. 文件管理  
文件存储空间的管理、目录管理、文件读写管理和保护等。
4. 设备管理  
完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。
主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

### 用户态和内核态
* 内核态与用户态是操作系统的两种运行级别
* 运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。
* 处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理机是可被抢占的；而处于核心态执行中的进程，则能访问所有的内存空间和对象，且所占有的处理机是不允许被抢占的。
* 为了安全性。在cpu的一些指令中，有的指令如果用错，将会导致整个系统崩溃。分了内核态和用户态后，当用户需要操作这些指令时候，内核为其提供了API，可以通过系统调用陷入内核，让内核去执行这些操作。

### 用户态到内核态的转换

1. 系统调用   
这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的ine 80h中断。 
2. 异常   
当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。 
3. 外围设备的中断   
当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 

### 中断
* 在中断出现之前，CPU对IO采用的是轮询的方式进行服务，这使的CPU纠结在某一个IO上，一直在等待它的响应，如果它不响应，CPU就在原地一直的等下去。这样就导致了其他IO口也在等待CPU的服务，如果某个IO出现了important or emergency affairs，CPU也抽不出身去响应这个IO。
* 中断控制的主要优点是只有在IO接口需要服务时才去响应它，使得CPU很淡定的做它自己的事情，只有IO口有需求的时候才去响应它。同时中断中也设计了中断优先级，来处理一些很紧急的事件。
* CPU获知了计算机中发生的某些事，暂停执行当前的程序，转而去执行处理该事件的程序，当这段程序执行完毕之后，CPU继续执行刚才的程序。整个过程称为中断处理
* 来自CPU外部的中断称为 外部中断，来自CPU内部的中断称为 内部中断。
* 外部中断按是否宕机可以分为 可屏蔽中断 和 不可屏蔽中断。
* 内部中断按中断是否正常又可分为 软中断 和 异常。

### 大内核和微内核
1. 大内核
   * 大内核是将操作系统功能作为一个紧密结合的整体放到内核。除了最基本的进程、线程管理、内存管理外，将文件系统，驱动，网络协议等等都集成在内核里面
   * 由于各模块共享信息，因此有很高的性能。
   * 缺点：稳定性差，开发过程中的bug经常会导致整个系统挂掉。
2. 微内核
   * 由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。内核中只有最基本的调度、内存管理。移出的部分根据分层的原则划分成若干服务，相互独立。
   * 在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。
   * 因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。
   * 稳定，驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃 



-----------------------
[参考资料](https://www.cnblogs.com/bajdcc/p/4707544.html)
# 进程与线程

### 进程线程区别
* 进程可以认为是程序执行的一个实例，进程是系统进行资源分配的最小单位，且每个进程拥有独立的地址空间；
* 线程是进程的一个实体，是进程的一条执行路径；比进程更小的独立运行的基本单位，一个程序至少有一个进程，一个进程至少有一个线程；


1. 系统开销不同  
 因为进程拥有独立的堆栈空间和数据段，所以每当启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，系统开销比较大，而线程不一样，线程拥有独立的堆栈空间，但是共享数据段，它们彼此之间使用相同的地址空间，共享大部分数据，切换速度也比进程快，效率高，但是正由于进程之间独立的特点，使得进程安全性比较高，也因为进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。一个线程死掉就等于整个进程死掉。
2. 体现在通信机制上面，正因为进程之间互不干扰，相互独立，进程的通信机制相对很复杂，譬如管道，信号，消息队列，共享内存，套接字等通信机制，而线程由于共享数据段所以通信机制很方便。。
3. 属于同一个进程的所有线程共享该进程的所有资源，包括文件描述符。而不同过的进程相互独立。
4. 线程必定也只能属于一个进程，而进程可以拥有多个线程而且至少拥有一个线程；


### 线程共享和私有的的资源
* 线程共享资源
    1. 堆  
       由于堆是在进程空间中开辟出来的，所以它是理所当然地被共享的；因此new出来的都是共享的（16位平台上分全局堆和局部堆，局部堆是独享的）
    2. 全局变量 
       它是与具体某一函数无关的，所以也与特定线程无关；因此也是共享的
    3. 静态变量 
       虽然对于局部变量来说，它在代码中是“放”在某一函数中的，但是其存放位置和全局变量一样，存于堆中开辟的.bss和.data段，是共享的
    4. 文件等公用资源  
       这个是共享的，使用这些公共资源的线程必须同步。Win32 提供了几种同步资源的方式，包括信号、临界区、事件和互斥体。
    5. 进程的当前目录和进程用户ID与进程组ID。
    6. 信号的处理器
* 线程独享资源  
   1. 线程ID  
      每个线程都有自己的线程ID，这个ID在本进程中是唯一的。进程用此来标识线程。  
   2. 寄存器组的值  
      由于线程间是并发运行的，每个线程有自己不同的运行线索，当从一个线程切换到另一个线程上 时，必须将原有的线程的寄存器集合的状态保存，以便将来该线程在被重新切换到时能得以恢复。  
   3. 线程的栈  
      栈是保证线程独立运行所必须的。线程函数可以调用函数，而被调用函数中又是可以层层嵌套的，所以线程必须拥有自己的函数堆栈， 使得函数调用可以正常执行，不受其他线程的影响。  
   4. 错误返回码  
      由于同一个进程中有很多个线程在同时运行，可能某个线程进行系统调用后设置了errno值，而在该 线程还没有处理这个错误，另外一个线程就在此时被调度器投入运行，这样错误值就有可能被修改。所以，不同的线程应该拥有自己的错误返回码变量。  
   5. 线程的信号屏蔽码  
      由于每个线程所感兴趣的信号不同，所以线程的信号屏蔽码应该由线程自己管理。但所有的线程都 共享同样的信号处理器。  
   6. 线程的优先级  
      由于线程需要像进程那样能够被调度，那么就必须要有可供调度使用的参数，这个参数就是线程的优先级。  

### 进程和线程的选择
进程与线程的选择取决以下几点
1. 需要频繁创建销毁的优先使用线程；因为对进程来说创建和销毁一个进程代价是很大的。
2. 线程的切换速度快，所以在需要大量计算，切换频繁时用线程，还有耗时的操作使用线程可提高应用程序的响应
3. 因为对CPU系统的效率使用上线程更占优，所以可能要发展到多机分布的用进程，多核分布用线程；
4. 并行操作时使用线程，如C/S架构的服务器端并发线程响应用户的请求；
5. 需要更稳定安全时，适合选择进程；需要速度时，选择线程更好。

### 进程的五种状态
1. 创建状态：进程正在被创建 
2. 就绪状态：进程被加入到就绪队列中等待CPU调度运行 
3. 执行状态：进程正在被运行 
4. 等待阻塞状态：进程因为某种原因，比如等待I/O，等待设备，而暂时不能运行。 
5. 终止状态：进程运行完毕 

### 进程间通信
Linux几乎支持全部UNIX进程间通信方法，包括管道（有名管道和无名管道）、消息队列、共享内存、信号量和套接字。其中前四个属于同一台机器下进程间的通信，套接字则是用于网络通信。  
* 管道
    * 无名管道
        * 无名管道是一种特殊的文件，这种文件只存在于内存中。
        * 无名管道只能用于父子进程或兄弟进程之间，必须用于具有亲缘关系的进程间的通信。
        * 无名管道只能由一端向另一端发送数据，是半双工方式，如果双方需要同时收发数据需要两个管道。
        * 相关接口：int pipe(int fd[2]);fd[2]：管道两端用fd[0]和fd[1]来描述，读的一端用fd[0]表示，写的一端用fd[1]表示。通信双方的进程中写数据的一方需要把fd[0]先close掉，读的一方需要先把fd[1]给close掉。
    * 有名管道：
        * 有名管道是FIFO文件，存在于文件系统中，可以通过文件路径名来指出。
        * 无名管道可以在不具有亲缘关系的进程间进行通信。
        * 相关接口：int mkfifo(const char *pathname, mode_t mode);pathname：即将创建的FIFO文件路径，如果文件存在需要先删除。mode：和open()中的参数相同。
* 消息队列
    * 消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。 (消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息； 
    * 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。 
    * 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。 
    * 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。 
* 共享内存
   * 进程可以将同一段共享内存连接到它们自己的地址空间，所有进程都可以访问共享内存中的地址，如果某个进程向共享内存内写入数据，所做的改动将立即影响到可以访问该共享内存的其他所有进程。
* 信号量
* 套接字
可用于不同主机之间的进程通信


### 线程间通信的方式: 
* 临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问； 
* 互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会多个线程同时访问 
* 信号量Semphare：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源.
   * P(SV):如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。 
   * V(SV)：如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。 
* 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 



### 线程同步
* 如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。
* 线程安全问题都是由全局变量及静态变量引起的。
* 若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。
* 解决方法
   * 加锁

### 互斥锁，读写锁，自旋锁
* 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。 
* 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。 
* 自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。 
* 互斥锁和读写锁的区别： 
   * 读写锁区分读者和写者，而互斥锁不区分 
   * 互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。 


### 线程池
* 即时创建，即使销毁策略的弊端   
一旦有个请求到达，就创建一个新的线程，由该线程执行任务，任务执行完毕之后，线程就退出。这就是”即时创建，即时销毁”的策略。尽管与创建进程相比，创建线程的时间已经大大的缩短，但是如果提交给线程的任务是执行时间较短，而且执行次数非常频繁，那么服务器就将处于一个不停的创建线程和销毁线程的状态。这笔开销是不可忽略的，尤其是线程执行的时间非常非常短的情况。
* 线程池
   * 在应用程序启动之后，就马上创建一定数量的线程，放入空闲的队列中。这些线程都是处于阻塞状态，这些线程只占一点内存，不占用CPU。当任务到来后，线程池将选择一个空闲的线程，将任务传入此线程中运行。当所有的线程都处在处理任务的时候，线程池将自动创建一定的数量的新线程，用于处理更多的任务。执行任务完成之后线程并不退出，而是继续在线程池中等待下一次任务。当大部分线程处于阻塞状态时，线程池将自动销毁一部分的线程，回收系统资源。
   * 需要大量的线程来完成任务，且完成任务的时间比较短；对性能要求苛刻的应用；对性能要求苛刻的应用
* 内存池
   * 在软件开发中，有些对象使用非常频繁，那么我们可以预先在堆中实例化一些对象，我们把维护这些对象的结构叫“内存池”。在需要用的时候，直接从内存池中拿，而不用从新实例化，在要销毁的时候，不是直接free/delete，而是返还给内存池。把那些常用的对象存在内存池中，就不用频繁的分配/回收内存，可以相对减少内存碎片，更重要的是实例化这样的对象更快，回收也更快。当内存池中的对象不够用的时候就扩容。
   * 内存池对象不是线程安全的，在多线程编程中，创建一个对象时必须加锁。


### 常用线程模型 
1. Future模型 
该模型通常在使用的时候需要结合Callable接口配合使用。 
Future是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。 
Callable是类似于Runnable的接口，其中call方法类似于run方法，所不同的是run方法不能抛出受检异常没有返回值，而call方法则可以抛出受检异常并可设置返回值。两者的方法体都是线程执行体。 
2. fork&join模型 
该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一些可以进行拆分的大任务。其主要是把一个大任务逐级拆分为多个子任务，然后分别在子线程中执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果。 
这里模拟一个摘苹果的场景：有100棵苹果树，每棵苹果树有10个苹果，现在要把他们摘下来。为了节约时间，规定每个线程最多只能摘10棵苹树以便于节约时间。各个线程摘完之后汇总计算总苹果树。 
3. actor模型 
actor模型属于一种基于消息传递机制并行任务处理思想，它以消息的形式来进行线程间数据传输，避免了全局变量的使用，进而避免了数据同步错误的隐患。actor在接受到消息之后可以自己进行处理，也可以继续传递（分发）给其它actor进行处理。在使用actor模型的时候需要使用第三方Akka提供的框架。 
4. 生产者消费者模型 
生产者消费者模型都比较熟悉，其核心是使用一个缓存来保存任务。开启一个/多个线程来生产任务，然后再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费者只需要从缓存中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。比如，生成的任务速度较快，那么就可以灵活的多开启几个消费者线程进行处理，这样就可以避免任务的处理响应缓慢的问题。 
5. master-worker模型 
master-worker模型类似于任务分发策略，开启一个master线程接收任务，然后在master中根据任务的具体情况进行分发给其它worker子线程，然后由子线程处理任务。如需返回结果，则worker处理结束之后把处理结果返回给master。 



### 协程
1) 是一种比线程更加轻量级的存在。正如一个进程可以拥有多个线程一样，一个线程可以拥有多个协程；协程不是被操作系统内核管理，而完全是由程序所控制。
2) 协程的开销远远小于线程；
3) 协程拥有自己寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切换回来的时候，恢复先前保存的寄存器上下文和栈。
4) 每个协程表示一个执行单元，有自己的本地数据，与其他协程共享全局数据和其他资源。
5) 跨平台、跨体系架构、无需线程上下文切换的开销、方便切换控制流，简化编程模型；
6) 协程又称为微线程，协程的完成主要靠yeild关键字，协程执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行；
7) 协程极高的执行效率，和多线程相比，线程数量越多，协程的性能优势就越明显；
8) 不需要多线程的锁机制；



### 僵尸进程和孤儿进程
* 父进程在调用fork接口之后和子进程已经可以独立开，之后父进程和子进程就以未知的顺序向下执行（异步过程）。所以父进程和子进程都有可能先执行完。
* 当父进程先结束，子进程此时就会变成孤儿进程，孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
* 僵尸进程 
   * 如果子进程先结束，父进程并未调用wait或者waitpid获取进程状态信息，那么子进程描述符就会一直保存在系统中，这种进程称为僵尸进程。
   * 保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。 
   * 解决方法
      * 通过kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源 
      * 子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。 
      * fork两次，原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。 

### 守护进程
守护进程是脱离终端并在后台运行的进程，执行过程中信息不会显示在终端上并且也不会被终端发出的信号打断。周期性地执行某种任务或等待处理某些发生的事件。

### fork和vfork
* fork
   * 创建一个和当前进程映像一样的进程可以通过fork()系统调用
   * 成功调用fork()会创建一个新的进程，它几乎与调用fork()的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork()调用会返回0。在父进程中fork()返回子进程的pid。如果出现错误，fork()返回一个负值
   * 常用的fork()用法是创建一个新的进程，然后使用exec()载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像
   * 当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的
* vfork
   * vfork()会挂起父进程直到子进程终止或者运行了一个新的可执行文件的映像。通过这样的方式，vfork()避免了地址空间的按页复制
* 写时复制
   * 减少fork时对父进程空间进程整体复制带来的开销
   * 采取了惰性优化方法来避免复制时的系统开销
   * 如果有多个进程要读取它们自己的那部门资源的副本，那么复制是不必要的.如果一个进程要修改自己的那份资源“副本”，那么就会复制那份资源，并把复制的那份提供给进程
   * 写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行




-------------------------------------
# 死锁

### 产生原因
* 死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的相互等待的现象。死锁发生的四个必要条件如下： 
   * 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源； 
   * 请求和保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源 
   * 不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放 
   * 环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链 

### 解决方法
* 鸵鸟策略
   * 因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。
   * 当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。
   * 大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。
* 死锁检测与死锁恢复
   * 不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。
   * 利用抢占恢复
   * 利用回滚恢复
   * 通过杀死进程恢复
* 死锁预防
   * 资源一次性分配，从而剥夺请求和保持条件 
   * 可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件 
   * 资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件 
* 死锁避免
   * 在程序运行时避免发生死锁。
   * 银行家算法


---------------------------------------
[参考资料](https://blog.csdn.net/XD_hebuters/article/details/79519406)
# 内存管理

## 内存管理需要满足的需求

1. 重定位
   * 进程多次在内存切入切出，放置于不同位置能力 
   * 一旦程序被换出到磁盘，当下一次换入时，如果必须放在和被换出前相同的内存区域，那么这将会是很大的限制。为了避免这种限制，需要把进程重定位到内存的不同区域。 
2. 保护
   * 保护进程的程序和数据不被未授权的进程访问和修改
   * 内存保护的需求必须有处理器硬件来满足，而不是操作系统（软件）来满足。这是因为操作系统不能够预测程序可能产生的所有的内存访问;即使可以预测，提前审查每个进程可能潜在的违法访问也是非常费时的，因此，只能在指令访问内存时来判断这个内存访问是否违法(存取数据或跳转)。为实现这一点，要求处理器有这个能力。 
3. 共享
   * 多个进程访问内存同一区域 
   * 如果多个进程在执行同一个程序，则允许每个进程访问该程序的同一个副本比每个进程都有自己的单独的副本更有优势
4. 逻辑组织
   * 把线性的地址空间组织成不同的模块
   * 可以独立编写和编译模块，系统在运行时解析一个模块到其他模块的所有引用。 
   * 通过适度的额外开销，可以给不同的模块以不同的保护级别（只读、只执行）。 
   * 可以引入某种机制，使得模块被多个进程共享。
5. 物理组织
   * 两级存储
   。内存提供快速的访问，成本高，并且内存是易失性的，不能提供永久存储。用于保存当前使用的程序或数据
   * 外存比内存慢且便宜，通常为非易失性的，用于长期存储程序和数据
   * 需要管理内存和磁盘间的信息流动


##  连续分配存储管理方式
连续分配是指为一个用户程序分配连续的内存空间。
#### 单一连续存储管理
* 整个内存里面只有两个程序：一个是用户程序，另外一个是操作系统。
* 应用程序装入到用户区，可使用用户区全部空间，并且总是加载到同一个内存地址上。即用户程序永远从同一个地方开始执行。
* 优点：管理非常简单，实际上不需要任何的内存管理单元，程序运行速度快，因为越过了地址翻译这个步骤
* 缺点：
   * 整个程序要加载到内存空间中去，这样将导致比物理内存大的程序无法运行。
   * 只运行一个程序造成资源浪费，如果一个程序很小，虽然占用内存空间小，但剩下的内存空间也无法使用
   * 可能无法在不同的操作系统下运行，因为不同操作系统所占用的内存空间大小可能不一样，使得用户程序的起始地址可能不一样

#### 分区式存储管理
* 把内存分为一些大小相等或不等的分区，操作系统占用其中一个分区，其余的分区由应用程序使用，每个应用程序占用一个或几个分区
* 可以支持并发，但难以进行内存分区的共享。
* 内碎片是占用分区内未被利用的空间
* 外碎片是占用分区之间难以利用的空闲分区(通常是小空闲分区)。
* 为实现分区式存储管理，操作系统应维护的数据结构为分区表或分区链表。表中各表项一般包括每个分区的起始地址、大小及状态(是否已分配)。
* 固定分区(nxedpartitioning)
   * 把内存划分为若干个固定大小的连续分区。
   * 分区大小可以相等：这种作法只适合于多个相同程序的并发执行(处理多个类型相同的对象)。
   * 分区大小也可以不等：有多个小分区、适量的中等分区以及少量的大分区。根据程序的大小，分配当前空闲的、适当大小的分区。
   * 优点：易于实现，开销小。
   * 缺点主要有两个：内碎片造成浪费；分区总数固定，限制了并发执行的程序数目。
* 动态分区(dynamic partitioning)
   * 动态创建分区：在装入程序时按其初始要求分配，或在其执行过程中通过系统调用进行分配或改变分区大小
   * 没有内碎片。但它却引入了另一种碎片——外碎片。
   * 寻找某个空闲分区，其大小需大于或等于程序的要求。若是大于要求，则将该分区分割成两个分区，其中一个分区为要求的大小并标记为“占用”，而另一个分区为余下部分并标记为“空闲”。分区释放过程中会将相邻的空闲分区合并成一个大的空闲分区
   * 常用的分区分配算法
      * 最先适配法(first-fit)：按分区在内存的先后次序从头查找，找到符合要求的第一个分区进行分配。该算法的分配和释放的时间性能较好，较大的空闲分区可以被保留在内存高端。但随着低端分区不断划分会产生较多小分区，每次分配时查找时间开销便会增大。
      * 下次适配法(循环首次适应算法 next fit)：按分区在内存的先后次序，从上次分配的分区起查找(到最后一个分区时再从头开始}，找到符合要求的第一个分区进行分配。该算法的分配和释放的时间性能较好，使空闲分区分布得更均匀，但较大空闲分区不易保留。
      * 最佳适配法(best-fit)：按分区在内存的先后次序从头查找，找到其大小与要求相差最小的空闲分区进行分配。从个别来看，外碎片较小；但从整体来看，会形成较多外碎片。优点是较大的空闲分区可以被保留。
      * 最坏适配法(worst- fit)：按分区在内存的先后次序从头查找，找到最大的空闲分区进行分配。基本不留下小空闲分区，不易形成外碎片。但由于较大的空闲分区不被保留，当对内存需求较大的进程需要运行时，其要求不易被满足。
* 伙伴系统
   *  固定分区和动态分区方式都有不足之处。
      * 固定分区方式限制了活动进程的数目，当进程大小与空闲分区大小不匹配时，内存空间利用率很低。
      * 动态分区方式算法复杂，回收空闲分区时需要进行分区合并等，系统开销较大。
      * 伙伴系统方式是对以上两种内存方式的一种折衷方案
   * 无论已分配分区或空闲分区，其大小均为 2 的 k 次幂，k 为整数， l≤k≤m，其中：
      * 2^l 表示分配的最小分区的大小，
      * 2^m 表示分配的最大分区的大小，2^m是整个可分配内存的大小。
   * 在系统运行过中，由于不断的划分，可能会形成若干个不连续的空闲分区，将这些空闲分区根据分区的大小进行分类，对于每一类具有相同大小的所有空闲分区，单独设立一个空闲分区双向链表。这样，不同大小的空闲分区形成了k(0≤k≤m)个空闲分区链表。  
   * 分配步骤
      * 当需要为进程分配一个长度为n 的存储空间时: 首先计算一个i 值，使 2^(i－1) < n ≤ 2^i，
      * 然后在空闲分区大小为2^i的空闲分区链表中查找。
      * 若找到，即把该空闲分区分配给进程。否则，表明长度为2^i的空闲分区已经耗尽，则在分区大小为2^(i＋1)的空闲分区链表中寻找。
      * 若存在 2^(i＋1)的一个空闲分区，则把该空闲分区分为相等的两个分区，这两个分区称为一对伙伴，其中的一个分区用于配，而把另一个加入分区大小为2^i的空闲分区链表中.若仍然找不到，则继续查找大小为 2^(i＋2)的空闲分区，以此类推。
   * 与一次分配可能要进行多次分割一样，一次回收也可能要进行多次合并，
* 内存紧缩
   * 将各个占用分区向内存一端移动，然后将各个空闲分区合并成为一个空闲分区。
   * 紧缩时机：每个分区释放后，或内存分配找不到满足条件的空闲分区时

### 覆盖和交换技术
* 覆盖
   * 引入覆盖 (overlay)技术的目标是在较小的可用内存中运行较大的程序。这种技术常用于多道程序系统之中，与分区式存储管理配合使用
   * 原理
      * 一个程序的几个代码段或数据段，按照时间先后来占用公共的内存空间。
      * 将程序必要部分(常用功能)的代码和数据常驻内存；
      * 可选部分(不常用功能)平时存放在外存(覆盖文件)中，在需要时才装入内存。不存在调用关系的模块不必同时装入到内存，从而可以相互覆盖。
      * 在任何时候只在内存中保留所需的指令和数据；当需要其它指令时，它们会装入到刚刚不再需要的指令所占用的内存空间；
   * 缺点是编程时必须划分程序模块和确定程序模块之间的覆盖关系，增加编程复杂度；从外存装入覆盖文件，以时间延长换取空间节省
* 交换
   * 在多个程序并发执行时，可以将暂时不能执行的程序（进程）送到外存中，从而获得空闲内存空间来装入新程序（进程），或读人保存在外存中而处于就绪状态的程
   * 交换单位为整个进程的地址空间
   * 交换技术优点之一是增加并发运行的程序数目，并给用户提供适当的响应时间；与覆盖技术相比交换技术另一个显著的优点是不影响程序结构。
   * 对换人和换出的控制增加处理器开销；程序整个地址空间都进行对换，没有考虑执行过程中地址访问的统计特性。
* 两者对比
   * 与覆盖技术相比，交换不要求程序员给出程序段之间的覆盖结构。
   * 交换主要是在进程与作业之间进行，而覆盖则主要在同一作业或进程内进行。 另外覆盖只能覆盖那些与覆盖程序段无关的程序段。

## 页式和段式存储管理
* 如果允许将一个进程分散到许多不连续的空间，就可以避免内存紧缩，减少碎片。基于这一思想，通过引入进程的逻辑地址，把进程地址空间与实际存储空间分离，增加存储管理的灵活性。
* 地址空间：将源程序经过编译后得到的目标程序，存在于它所限定的地址范围内，这个范围称为地址空间。地址空间是逻辑地址的集合。
* 存储空间：指主存中一系列存储信息的物理单元的集合，这些单元的编号称为物理地址。存储空间是物理地址的集合。
* 根据分配时所采用的基本单位不同，可将离散分配的管理方式分为以下三种：页式存储管理、段式存储管理和段页式存储管理。其中段页式存储管理是前两种结合的产物。

### 页式存储管理
* 将程序的逻辑地址空间划分为固定大小的页(page)，而物理内存划分为同样大小的页框(page frame)。程序加载时，可将任意一页放入内存中任意一个页框，这些页框不必连续，从而实现了离散分配
* 需要CPU的硬件支持(内存管理单元（MMU）)，来实现逻辑地址和物理地址之间的映射。在页式存储管理方式中地址结构由两部构成，前一部分是页号，后一部分为页内地址w（位移量）

### 段式存储管理
段式存储管理要求每个作业的地址空间按照程序自身的逻辑划分为若干段，每个段都有一个唯一的内部段号。
逻辑地址由段号S与段内偏移量W两部分组成。
### 段页式存储管理
在段页式存储中，每个分段又被分成若干个固定大小的页。
逻辑地址由段号S、段内页号P与页内偏移量W两部分组成。
[1](https://blog.csdn.net/guoweimelon/article/details/50853719)
[2](https://blog.csdn.net/hguisu/article/details/5713164)

### 段页式管理每一次数据要访问几次内存? 
三次
第一次是由段表地址寄存器得段表始址后访问段表，由此取出对应段的页表在内存中的地址。 第二次则是访问页表得到所要访问的物理地址。 第三次才能访问真正需要访问的物理单元。




### 页和段的区别

1. 页是信息的物理单位，分页是由于系统管理的需要。段是信息的逻辑单位，分段是为了满足用户的要求。
2. 页的大小固定且由系统决定，段的长度不固定，决定于用户所编写的程序，通常由编译程序在对源程序紧进行编译时，根据信息的性质来划分。
3. 分页的作业的地址空间是一维的，程序员只需要利用一个记忆符，即可表示一个地址。分段的作业地址空间则是二维的，程序员在标识一个地址时，既需要给出段名，又需要给出段的地址值。


























### 虚拟内存与物理内存
* 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。
* 为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。
* 从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。

### 分页系统地址映射
* 内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。
* 一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

### 虚拟内存的好处和代价
* 好处
   1.扩大地址空间； 
   2.内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。 
   3.公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。 
   4.当进程通信时，可采用虚存共享的方式实现。 
   5.当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存 
   6.虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高 
   7.在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片 
* 代价 
   1.虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存 
   2.虚拟地址到物理地址的转换，增加了指令的执行时间。 
   3.页面的换入换出需要磁盘I/O，这是很耗时的 
   4.如果一页中只有一部分数据，会浪费内存。 

### 缺页置换方法
当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。

* 先进先出(FIFO)算法：
   * 置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。
   * 按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。 
* LFU（最不经常访问淘汰算法） 
   * 如果数据过去被访问多次，那么将来被访问的频率也更高。 
   * 每个数据块一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。每次淘汰队尾数据块
* 最近最少使用（LRU）算法
   * 置换最近一段时间以来最长时间未访问过的页面。
   * 根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。 
   * 缓存颠簸，当缓存（1，2，3）满了，之后数据访问（0，3，2，1，0，3，2，1。。。）。 
   * 缓存污染，突然大量偶发性的数据访问，会让内存中存放大量冷数据。 
* LRU-K（LRU-2、LRU-3） 
   * 最久未使用K次淘汰算法。
   * LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。 


### LRU的实现
利用链表和hashmap。当需要插入新的数据项的时候，如果新数据命中，则把该节点放到链表头部，如果不存在，则将新数据放在链表头部。若缓存满了，则将链表尾部的节点删除。


### 内存溢出和内存泄漏
* 内存溢出 
   * 指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实际分配给你的空间，此时系统相当于没法满足你的需求，就会报内存溢出的错误 
   * 内存溢出原因： 
      * 内存中加载的数据量过于庞大，如一次从数据库取出过多数据 
      * 集合类中有对对象的引用，使用完后未清空，使得不能回收 
      * 代码中存在死循环或循环产生过多重复的对象实体 
      * 使用的第三方软件中的BUG 
      * 启动参数内存值设定的过小 
* 内存泄漏 
   * 内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。  
   * 堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。 
   * 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。
   * 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。 
---------------------------------------------------